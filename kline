package com.helei.dto.indicator;

import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;

import java.io.Serial;

@Data
@AllArgsConstructor
@NoArgsConstructor
public class Boll implements Indicator {

    @Serial
    private static final long serialVersionUID = -21358767865645L; // 显式声明 serialVersionUID

    private Double sma;

    private Double upper;

    private Double lower;

    @Override
    public Indicator clone() {
        return null;
    }
}


package com.helei.dto.indicator;


import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;

import java.io.Serial;

/**
 * EMA
 */
@Data
@AllArgsConstructor
@NoArgsConstructor
public class EMA implements Indicator {


    @Serial
    private static final long serialVersionUID = -128328476328234L; // 显式声明 serialVersionUID

    /**
     * ema值
     */
    private Double ema;


    @Override
    public EMA clone() {
        return new EMA(ema);
    }
}
package com.helei.dto.indicator;

import java.io.Serializable;

/**
 * 指标接口
 */
public interface Indicator extends Serializable {


    Indicator clone();
}



package com.helei.dto.indicator;


        import lombok.AllArgsConstructor;
        import lombok.Data;
        import lombok.NoArgsConstructor;

        import java.io.Serial;

/**
 * MA指标数据
 */
@Data
@AllArgsConstructor
@NoArgsConstructor
public class MA implements Indicator {

    @Serial
    private static final long serialVersionUID = -1516541354154L; // 显式声明 serialVersionUID

    /**
     * 值
     */
    private Double ma;

    @Override
    public MA clone() {
        return new MA(ma);
    }
}
package com.helei.dto.indicator;

import lombok.*;

import java.io.Serial;

@Data
@AllArgsConstructor
@NoArgsConstructor
@ToString
public class MACD implements Indicator {
    @Serial
    private static final long serialVersionUID = -5187464594186468L; // 显式声明 serialVersionUID

    private Double ema1 = 0.0;

    private Double ema2 = 0.0;

    /**
     * macd dea 慢线
     */
    private Double dea = 0.0;

    /**
     * macd dif 快线
     * @return dif值
     */
    public Double dif() {
        return ema1 - ema2;
    }

    /**
     * macd柱状图
     * @return 高度
     */
    public Double macdHistogram() {
        return  2 * (dif() - dea);
    }

    @Override
    public Indicator clone() {
        return new MACD(ema1, ema2, dea);
    }
}
package com.helei.dto.indicator;

import com.helei.dto.TrendLine;
import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;

import java.io.Serial;
import java.io.Serializable;
import java.util.List;

/**
 * 支撑、压力、趋势线
 */
@Data
@AllArgsConstructor
@NoArgsConstructor
@Builder
public class PST implements Indicator, Serializable {

    @Serial
    private static final long serialVersionUID = -1451638498435687779L; // 显式声明 serialVersionUID


    /**
     * 压力线
     */
    private List<Double> pressure;

    /**
     * 支撑线
     */
    private List<Double> support;

    /**
     * 上趋势线,根据相对高点计算
     */
    private TrendLine relativeUpTrendLine;

    /**
     * 下趋势线，根据相对低点计算
     */
    private TrendLine relativeDownTrendLine;

    /**
     * 最大值
     */
    private double maxPrice;

    /**
     * 最小值
     */
    private double minPrice;

    @Override
    public Indicator clone() {
        return new PST(pressure, support, relativeUpTrendLine, relativeDownTrendLine, maxPrice, minPrice);
    }

}

package com.helei.dto.indicator;


        import lombok.AllArgsConstructor;
        import lombok.Data;
        import lombok.NoArgsConstructor;

        import java.io.Serial;

@Data
@AllArgsConstructor
@NoArgsConstructor
public class RSI implements Indicator{
    @Serial
    private static final long serialVersionUID = -54898746849844784L; // 显式声明 serialVersionUID


    private Double rsi;

    @Override
    public Indicator clone() {
        return new RSI(rsi);
    }
}
package com.helei.dto;

import com.helei.dto.indicator.Indicator;
import com.helei.dto.indicator.config.IndicatorConfig;
import lombok.Getter;
import lombok.Setter;

import java.util.UUID;
import java.util.concurrent.ConcurrentHashMap;

@Setter
@Getter
public class IndicatorMap {

    private final ConcurrentHashMap<String, Indicator> map;


    public IndicatorMap() {
        this.map = new ConcurrentHashMap<>();
    }

    private String uuid = UUID.randomUUID().toString();

    public <T extends Indicator> T getIndicator(IndicatorConfig<T> config) {
        return (T) getIndicator(config.getIndicatorName());
    }
    public Indicator getIndicator(String indicatorName) {
        return map.get(indicatorName);
    }

    public void put(IndicatorConfig<? extends Indicator> indicatorConfig, Indicator indicator) {
        map.put(indicatorConfig.getIndicatorName(), indicator);
    }

    @Override
    public String toString() {
        return "IndicatorMap{" +
                "map=" + map +
                '}' + "uuide=" + uuid;
    }
}
package com.helei.dto;

import com.helei.constants.KLineInterval;
import com.helei.dto.indicator.Indicator;
import com.helei.dto.indicator.config.IndicatorConfig;
import lombok.*;

import java.io.Serial;
import java.io.Serializable;
import java.time.Instant;

/**
 * K线实体类
 */
@Data
@AllArgsConstructor
@NoArgsConstructor
@EqualsAndHashCode
@Builder
public class KLine implements Serializable {

    @Serial
    private static final long serialVersionUID = 8888L; // 显式声明 serialVersionUID

    public  static final KLine HISTORY_END_KLINE = KLine.builder().symbol("HISTORY_END_KLINE").build();

    public  static final KLine STREAM_END_KLINE = KLine.builder().symbol("STREAM_END_KLINE").build();

    /**
     * symbol
     */
    private String symbol = "";

    /**
     * 开盘价格
     */
    private double open;

    /**
     * 收盘价格
     */
    private double close;

    /**
     * 最高价格
     */
    private double high;

    /**
     * 最低价格
     */
    private double low;

    /**
     * 成交量
     */
    private double volume;

    /**
     * 开盘时间
     */
    private long openTime;

    /**
     * 收盘时间
     */
    private long closeTime;


    /**
     * 这根线是否执行完
     */
    private boolean end;

    /**
     * k线频率
     */
    private KLineInterval kLineInterval;

    /**
     * 存放各种指标以及他的值
     */
    private IndicatorMap indicators = new IndicatorMap();


    public <T extends Indicator> T getIndicator(IndicatorConfig<T> config) {
        return indicators.getIndicator(config);
    }

    /**
     * 获取stream流名称
     * @return stream流名称
     */
    public String getStreamKey() {
        return  getKLineStreamKey(symbol, kLineInterval);
    }

    public static String getKLineStreamKey(String symbol, KLineInterval kLineInterval) {
        return symbol + "@kline_" + kLineInterval.getDescribe();
    }

    @Override
    public String toString() {
        return "KLine{" +
                "symbol='" + symbol + '\'' +
                ", open=" + open +
                ", close=" + close +
                ", high=" + high +
                ", low=" + low +
                ", volume=" + volume +
                ", openTime=" + Instant.ofEpochMilli(openTime) +
                ", closeTime=" + Instant.ofEpochMilli(closeTime) +
                ", end=" + end +
                ", indicators=" + indicators +
                '}';
    }

    public KLine clone() {
        return KLine.builder().symbol(symbol).open(open).close(close).high(high).low(low).volume(volume).openTime(openTime).closeTime(closeTime).end(end).indicators(indicators).kLineInterval(kLineInterval).build();
    }

}

package com.helei.dto;

import com.helei.constants.KLineInterval;
import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.EqualsAndHashCode;
import lombok.NoArgsConstructor;

@Data
@AllArgsConstructor
@NoArgsConstructor
@EqualsAndHashCode
public class SignalGroupKey {
    private String symbol;

    private KLineInterval interval;

    public String getStreamKey() {
        return KLine.getKLineStreamKey(symbol, interval);
    }
}


package com.helei.dto;

import com.helei.constants.TradeSide;
import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;



/**
 * 交易信号
 */
@Data
@AllArgsConstructor
@NoArgsConstructor
@Builder
public class TradeSignal {

    /**
     * 信号名
     */
    private String name;

    /**
     * 信号描述
     */
    private String description;

    /**
     * 发出这个信号的k线
     */
    private KLine kLine;

    /**
     * 当前时间
     */
    private Long createTime;

    /**
     * 交易方向
     */
    private TradeSide tradeSide;

    /**
     * 当前价格
     */
    private Double currentPrice;

    /**
     * 目标价格
     */
    private Double targetPrice;

    /**
     * 止损价格
     */
    private Double stopPrice;

    /**
     * 信号是否过期
     */
    private Boolean isExpire;

    /**
     * 获取信号流的名字
     *
     * @return streamName
     */
    public String getStreamKey() {
        return kLine.getStreamKey();
    }


    public String getKlineStreamKey() {
        return kLine.getStreamKey();
    }
}

package com.helei.dto;


import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;

import java.io.Serializable;
import java.time.LocalDateTime;
import java.time.ZoneOffset;

/**
 * 趋势线，本质是一根直线。k m 为点斜式的斜率和偏移
 * TrendLine.calculateTrend() 采用最小二乘法计算趋势线
 */
@Data
@AllArgsConstructor
@NoArgsConstructor
public class TrendLine implements Serializable {
    private double k;
    private double m;

    public double predictPrice(LocalDateTime dateTime) {
        return k*dateTime.toInstant(ZoneOffset.UTC).getEpochSecond() + m;
    }
}

package com.helei.tradesignalcenter.config;

import org.apache.flink.configuration.*;
import org.apache.flink.streaming.api.TimeCharacteristic;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;

import java.net.URL;


public class FlinkConfig {

    private static final String CONFIG_FILE = "flink-conf";

    public static StreamExecutionEnvironment streamExecutionEnvironment() {
        // 创建 Flink 配置对象
        URL url = TradeSignalConfig.class.getClassLoader().getResource(CONFIG_FILE);

        if (url == null) {
            throw new RuntimeException("Failed to load YAML file: " + CONFIG_FILE);
        }

        Configuration config = GlobalConfiguration.loadConfiguration(url.getPath());
        // 设置 taskmanager.memory.network.fraction, 比例设为 15%
        config.setDouble(String.valueOf(TaskManagerOptions.NETWORK_MEMORY_FRACTION), 0.15);

        // 设置固定的网络内存大小，例如 128 MB
        config.set(TaskManagerOptions.NETWORK_MEMORY_MIN, MemorySize.ofMebiBytes(1024));
        return StreamExecutionEnvironment
                .createLocalEnvironment(config);
    }

    public StreamExecutionEnvironment streamExecutionEnvironment2() {
        // 创建 Flink 配置对象
        org.apache.flink.configuration.Configuration config = new org.apache.flink.configuration.Configuration();

        // 设置 taskmanager.memory.network.fraction, 比例设为 15%
        config.setDouble(String.valueOf(TaskManagerOptions.NETWORK_MEMORY_FRACTION), 0.15);

        // 设置固定的网络内存大小，例如 128 MB
        config.set(TaskManagerOptions.NETWORK_MEMORY_MIN, MemorySize.ofMebiBytes(1024));


        // 创建 Flink 流执行环境
        StreamExecutionEnvironment env = StreamExecutionEnvironment
                .createLocalEnvironment(config);
        env.setStreamTimeCharacteristic(TimeCharacteristic.ProcessingTime);
//                .createRemoteEnvironment(jobManagerHost, jobManagerPort);
        // 可选的其他配置
        // env.setParallelism(4);  // 设置并行度
        return env;
    }
}
package com.helei.tradesignalcenter.config;

import com.helei.constants.TradeType;
import com.helei.tradesignalcenter.constants.RunEnv;
import lombok.Data;
import org.yaml.snakeyaml.Yaml;

import java.io.InputStream;
import java.io.Serializable;
import java.util.Map;

@Data
public class TradeSignalConfig implements Serializable {
    private static final String CONFIG_FILE = "trade-signal-config.yaml";

    public static final TradeSignalConfig TRADE_SIGNAL_CONFIG;

    /**
     * 信号名
     */
    private String name;

    /**
     * 信号交易对
     */
    private String symbol;

    /**
     * 运行环境，测试网或者普通网
     */
    private RunEnv run_env;

    /**
     * 交易类型
     */
    private TradeType trade_type;

    /**
     * 历史k线加载批大小
     */
    private int historyKLineBatchSize;

    /**
     * 批加载并发度
     */
    private int batchLoadConcurrent;

    /**
     * 实时数据配置
     */
    private RealtimeConfig realtime;

    static {
        Yaml yaml = new Yaml();
        try (InputStream inputStream = TradeSignalConfig.class.getClassLoader().getResourceAsStream(CONFIG_FILE)) {
            if (inputStream == null) {
                throw new IllegalArgumentException("File not found: " + CONFIG_FILE);
            }
            Map<String, Object> yamlData = yaml.load(inputStream);
            Map<String, Object> shinano = (Map<String, Object>) yamlData.get("shinano");
            Map<String, Object> quantity = (Map<String, Object>) shinano.get("quantity");
            Map<String, Object> trade_signal_maker = (Map<String, Object>) quantity.get("trade_signal_maker");


            TRADE_SIGNAL_CONFIG = yaml.loadAs(yaml.dump(trade_signal_maker), TradeSignalConfig.class);

        } catch (Exception e) {
            throw new RuntimeException("Failed to load YAML file: " + CONFIG_FILE, e);
        }
    }

    private TradeSignalConfig() {}

    public String getSinkTopic() {
        return run_env.name() + "." + trade_type + "." + symbol + "." + name;
    }


    @Data
    public static class RealtimeConfig  implements Serializable  {

        private RealtimeKafkaConfig kafka;

        private RealtimeFlinkConfig flink;

    }


    @Data
    public static class RealtimeKafkaConfig  implements Serializable  {

        /**
         * 输入的配置
         */
        private KafkaServerConfig input;

        /**
         * 输出的配置
         */
        private KafkaServerConfig output;

    }

    @Data
    public static class KafkaServerConfig  implements Serializable  {
        /**
         * kafka集群连接地址
         */
        private String bootstrapServer;

        /**
         * 消费者组名
         */
        private String groupId;

        /**
         * 事务超时时间，需要比kafka broker 中设置的小
         */
        private String transaction_timeout_ms;
    }

    @Data
    public static class RealtimeFlinkConfig  implements Serializable  {

        /**
         * flink job manager host
         */
        private String jobManagerHost;
        /**
         * flink job manager port
         */
        private Integer jobManagerPort;
    }

    public static void main(String[] args) {
        System.out.println(TRADE_SIGNAL_CONFIG);
    }

}

package com.helei.tradesignalcenter.serialization;

import com.esotericsoftware.kryo.Kryo;
import com.esotericsoftware.kryo.Serializer;
import com.esotericsoftware.kryo.io.Input;
import com.esotericsoftware.kryo.io.Output;
import com.helei.dto.IndicatorMap;
import com.helei.dto.indicator.Indicator;
import lombok.extern.slf4j.Slf4j;

import java.io.*;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;

@Slf4j
public class IndicatorMapSerializer extends Serializer<IndicatorMap> {

    @Override
    public void write(Kryo kryo, Output output, IndicatorMap indicatorMap) {

        output.writeString(indicatorMap.getUuid());
        int size = indicatorMap.getMap().entrySet().size();
        log.debug("序列化 [{}]  size [{}]", indicatorMap, size);
        output.writeInt(size );
        try (ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream();
             ObjectOutputStream objectOutputStream = new ObjectOutputStream(byteArrayOutputStream);
        ) {
            for (Map.Entry<String, Indicator> entry : indicatorMap.getMap().entrySet()) {
                objectOutputStream.writeObject(entry.getKey());
                objectOutputStream.writeObject(entry.getValue());
            }
            byte[] byteArray = byteArrayOutputStream.toByteArray();
            output.writeInt(byteArray.length);
            output.writeBytes(byteArray);
        } catch (IOException e) {
            throw new RuntimeException(e);
        }
    }

    @Override
    public IndicatorMap read(Kryo kryo, Input source, Class<IndicatorMap> aClass) {
        String uuid = source.readString();
        IndicatorMap indicatorMap = new IndicatorMap();
        indicatorMap.setUuid(uuid);

        int size = source.readInt();
        int len = source.readInt();
        byte[] bytes = new byte[len];
        source.readBytes(bytes);

        ConcurrentHashMap<String, Indicator> indicators = indicatorMap.getMap();
        try (ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(bytes);
             ObjectInputStream objectInputStream = new ObjectInputStream(byteArrayInputStream)) {
            for (int i = 0; i < size; i++) {
                try {
                    String key = (String) objectInputStream.readObject();
                    Indicator value = (Indicator) objectInputStream.readObject();
                    indicators.put(key, value);
                }catch (EOFException e) {
                    log.error("反序列化出错， 已序列化出的结果:[{}]", indicatorMap, e);
                }
            }
        } catch (ClassNotFoundException | IOException e) {
            log.error("反序列化出错， 已序列化出的结果:[{}]", indicatorMap, e);
            throw new RuntimeException(e);
        }

        log.debug("反序列化得到 [{}]", indicatorMap);
        return indicatorMap;
    }
}
package com.helei.tradesignalcenter.serialization;

import com.esotericsoftware.kryo.Kryo;
import com.esotericsoftware.kryo.Serializer;
import com.esotericsoftware.kryo.io.Input;
import com.esotericsoftware.kryo.io.Output;
import com.helei.constants.KLineInterval;
import com.helei.dto.KLine;
import org.apache.flink.api.common.typeutils.TypeSerializer;
import org.apache.flink.api.common.typeutils.TypeSerializerSnapshot;
import org.apache.flink.core.memory.DataInputView;
import org.apache.flink.core.memory.DataOutputView;

import java.io.IOException;

public class KLineIntervalSerializer extends Serializer<KLineInterval> {

    @Override
    public void write(Kryo kryo, Output output, KLineInterval kLineInterval) {
        output.writeString(kLineInterval.getDescribe());
    }

    @Override
    public KLineInterval read(Kryo kryo, Input input, Class<KLineInterval> aClass) {
        return KLineInterval.STATUS_MAP.get(input.readString());
    }
}
package com.helei.tradesignalcenter.serialization;

import com.esotericsoftware.kryo.Kryo;
import com.esotericsoftware.kryo.Serializer;
import com.esotericsoftware.kryo.io.Input;
import com.esotericsoftware.kryo.io.Output;
import com.helei.constants.KLineInterval;
import com.helei.dto.IndicatorMap;
import com.helei.dto.KLine;

public class KLineSerializer extends Serializer<KLine> {


    @Override
    public void write(Kryo kryo, Output output, KLine kLine) {
        output.writeString(kLine.getSymbol());
        output.writeDouble(kLine.getOpen());
        output.writeDouble(kLine.getClose());
        output.writeDouble(kLine.getHigh());
        output.writeDouble(kLine.getLow());
        output.writeDouble(kLine.getVolume());
        output.writeLong(kLine.getOpenTime());
        output.writeLong(kLine.getCloseTime());
        output.writeBoolean(kLine.isEnd());

        Serializer klineIntervalSerializer = kryo.getSerializer(KLineInterval.class);
        Serializer indicatorMapSerializer = kryo.getSerializer(IndicatorMap.class);

        klineIntervalSerializer.write(kryo, output, kLine.getKLineInterval());

        indicatorMapSerializer.write(kryo, output, kLine.getIndicators());
    }

    @Override
    public KLine read(Kryo kryo, Input input, Class<KLine> aClass) {
        String symbol = input.readString();
        double open = input.readDouble();
        double close = input.readDouble();
        double high = input.readDouble();
        double low = input.readDouble();
        double volume = input.readDouble();
        long openTime = input.readLong();
        long closeTime = input.readLong();
        boolean end = input.readBoolean();

        Serializer klineIntervalSerializer = kryo.getSerializer(KLineInterval.class);
        Serializer indicatorMapSerializer = kryo.getSerializer(IndicatorMap.class);


        KLineInterval kLineInterval = (KLineInterval) klineIntervalSerializer.read(kryo, input, KLineInterval.class);
        IndicatorMap indicatorMap = (IndicatorMap) indicatorMapSerializer.read(kryo, input, IndicatorMap.class);


        return KLine.builder()
                .symbol(symbol)
                .open(open)
                .close(close)
                .high(high)
                .low(low)
                .volume(volume)
                .openTime(openTime)
                .closeTime(closeTime)
                .end(end)
                .kLineInterval(kLineInterval)
                .indicators(indicatorMap)
                .build();
    }
}
package com.helei.tradesignalcenter.stream.a_datasource;


import com.helei.binanceapi.BinanceWSApiClient;
import com.helei.binanceapi.api.ws.BinanceWSStreamApi;
import com.helei.cexapi.CEXApiFactory;
import com.helei.constants.KLineInterval;
import com.helei.constants.WebSocketStreamParamKey;
import com.helei.binanceapi.constants.WebSocketStreamType;
import com.helei.binanceapi.dto.StreamSubscribeEntity;
import com.helei.binanceapi.supporter.KLineMapper;
import com.helei.dto.KLine;
import com.helei.tradesignalcenter.util.KLineBuffer;
import com.helei.util.CustomBlockingQueue;
import lombok.extern.slf4j.Slf4j;


import javax.net.ssl.SSLException;
import java.net.URISyntaxException;
import java.util.List;
import java.util.UUID;
import java.util.concurrent.*;


/**
 * 订阅k线，分发数据。
 * 1。创建类时自动链接Binance
 * 2.调用addListenKLine会向Binance api请求k线数据推送
 * 3.需要k线数据需要调用registry() 方法注册订阅
 * 最后，2步骤中得到推送的k线数据后，会遍历订阅者进行发送
 */
@Slf4j
@Deprecated

public class MemoryKLineDataPublisher implements KLineDataPublisher {

    private final ExecutorService publishExecutor;

    /**
     * 获取流实时数据
     */
    private final BinanceWSStreamApi streamApi;

    /**
     * 普通api 用于获取历史数据
     */
    private final HistoryKLineLoader historyKLineLoader;

    /**
     * 实时k线数据buffer
     */
    private final ConcurrentMap<String, CustomBlockingQueue<KLine>> realTimeKLineBufferMap = new ConcurrentHashMap<>();

    private final int bufferSize;

    /**
     * 加载发布k线数据
     * @param streamUrl        streamUrl
     * @param requestUrl       requestUrl
     * @param bufferSize       实时数据缓存区大小
     * @param historyLoadBatch 历史数据一次拉取的批大小
     * @param publishExecutor     处理线程池，由于registry()返回的KLineBuffer()是有界的，长时间不消费可能会导致处理的线程池县城被长期阻塞。
     */
    public MemoryKLineDataPublisher(
            String streamUrl,
            String requestUrl,
            int bufferSize,
            int historyLoadBatch,
            ExecutorService publishExecutor
    ) throws URISyntaxException, SSLException, ExecutionException, InterruptedException {
        this(
                CEXApiFactory.binanceApiClient(streamUrl),
                CEXApiFactory.binanceApiClient(requestUrl),
                bufferSize,
                historyLoadBatch,
                publishExecutor
        );
    }

    /**
     * 加载发布k线数据
     *
     * @param streamClient     streamClient
     * @param normalClient     normalClient
     * @param bufferSize       实时数据缓存区大小
     * @param historyLoadBatch 历史数据一次拉取的批大小
     * @param publishExecutor     处理线程池，由于registry()返回的KLineBuffer()是有界的，长时间不消费可能会导致处理的线程池县城被长期阻塞。
     */
    public MemoryKLineDataPublisher(
            BinanceWSApiClient streamClient,
            BinanceWSApiClient normalClient,
            int bufferSize,
            int historyLoadBatch,
            ExecutorService publishExecutor
    ) throws URISyntaxException, SSLException, ExecutionException, InterruptedException {
        CompletableFuture.allOf(streamClient.connect(), normalClient.connect()).get();

        this.publishExecutor = publishExecutor;
        streamClient.setName("实时k线获取客户端-" + UUID.randomUUID().toString().substring(0, 8));
        normalClient.setName("历史k线获取客户端-" + UUID.randomUUID().toString().substring(0, 8));
        this.historyKLineLoader = new HistoryKLineLoader(historyLoadBatch, normalClient, publishExecutor);

        streamApi = streamClient.getStreamApi();

        this.bufferSize = bufferSize;

        log.info("初始化MemoryKLineDataPublisher成功");
    }

    /**
     * 获取哪些k线
     *
     * @param symbol       symbol
     * @param intervalList intervalList
     * @return KLineDataPublisher
     */
    @Override
    public MemoryKLineDataPublisher addListenKLine(
            String symbol,
            List<KLineInterval> intervalList
    ) {
        BinanceWSStreamApi.StreamCommandBuilder streamCommandBuilder = streamApi.builder();
        streamCommandBuilder.symbol(symbol);

        intervalList.forEach(kLineInterval -> {
            String key = getKLineMapKey(symbol, kLineInterval);

            final CustomBlockingQueue<KLine> buffer = new CustomBlockingQueue<>(bufferSize);
            realTimeKLineBufferMap.put(key, buffer);

            streamCommandBuilder.addSubscribeEntity(
                    StreamSubscribeEntity
                            .builder()
                            .symbol(symbol)
                            .subscribeType(WebSocketStreamType.KLINE)
                            .invocationHandler((streamName, result) -> {
                                //分发订阅的k线
                                KLine kLine = KLineMapper.mapJsonToKLine(result);
                                kLine.setKLineInterval(kLineInterval);
                                dispatchKLineData(key, kLine);
                            })
                            .callbackExecutor(publishExecutor)
                            .build()
                            .addParam(WebSocketStreamParamKey.KLINE_INTERVAL, kLineInterval.getDescribe())
            );
        });
        streamCommandBuilder.subscribe();
        return this;
    }

    /**
     * 对订阅者分发k线数据
     *
     * @param key   key
     * @param kLine kLine
     */
    private void dispatchKLineData(String key, KLine kLine) {
        CustomBlockingQueue<KLine> buffer = realTimeKLineBufferMap.get(key);
        if (buffer == null) {
            log.warn("no kline data buffer [{}]", key);
        } else {
            buffer.offer(kLine);
        }
    }


    /**
     * 注册监听k线， 不及时消费可能会阻塞线程池！
     *
     * @param symbol   symbol
     * @param interval interval
     * @return SubscribeData
     */
    public KLineBuffer registry(String symbol, KLineInterval interval, long startTime) {

        String bufferKey = getKLineMapKey(symbol, interval);

        CustomBlockingQueue<KLine> buffer = realTimeKLineBufferMap.get(bufferKey);

        if (buffer == null) {
            throw new IllegalArgumentException("this publisher didn't listen kline: " + bufferKey);
        }

        KLineBuffer kb = new KLineBuffer(bufferSize);
        historyKLineLoader.startLoad(
                symbol,
                interval,
                startTime,
                kLineList -> {
                    try {
                        for (KLine kLine : kLineList) {
                            kLine.setKLineInterval(interval);
                            kb.put(kLine);
                        }
                    } catch (InterruptedException e) {
                        log.error("put kline data into kline buffer [{}] error", kb, e);
                        throw new RuntimeException(e);
                    }
                }
        ).thenAcceptAsync((endTime) -> {
            try {
                KLine kLine = null;
                while ((kLine = buffer.take()) != null && !KLine.STREAM_END_KLINE.equals(kLine)) {
                    kb.put(kLine);
                    log.debug("put real time kline, current kline buffer size[{}]", kb.size());
                }
            } catch (InterruptedException e) {
                log.error("put kline data into kline buffer [{}] error", kb, e);
                throw new RuntimeException(e);
            }
        }, publishExecutor);
        return kb;
    }


    /**
     * 计算key
     *
     * @param symbol        symbol
     * @param kLineInterval kLineInterval
     * @return key
     */
    private static String getKLineMapKey(String symbol, KLineInterval kLineInterval) {
        return symbol + "-" + kLineInterval.getDescribe();
    }

}
package com.helei.tradesignalcenter.stream.a_datasource;

import com.helei.constants.KLineInterval;
import com.helei.dto.IndicatorMap;
import com.helei.dto.KLine;
import com.helei.tradesignalcenter.stream.a_klinesource.KLineHisAndRTSource;
import org.apache.flink.configuration.Configuration;

import java.time.LocalDateTime;
import java.time.ZoneOffset;
import java.util.HashMap;
import java.util.Random;
import java.util.Set;
import java.util.concurrent.*;


public class RandomKLineSource extends KLineHisAndRTSource {
    private transient ExecutorService executorService;

    private final ConcurrentHashMap<KLineInterval, Long> startTimeStampMap;

    private final Random random = new Random();

    private final Double maxPrice;

    private final Double minPrice;

    private final ConcurrentHashMap<KLineInterval, Long> realTimerMap;


    public RandomKLineSource(
            String symbol,
            Set<KLineInterval> kLineInterval,
            LocalDateTime startTimeStamp,
            Double maxPrice,
            Double minPrice
    ) {
        super(symbol, kLineInterval, startTimeStamp.toInstant(ZoneOffset.UTC).toEpochMilli());

        long epochMilli = startTimeStamp.toInstant(ZoneOffset.UTC).toEpochMilli();
        if (epochMilli > System.currentTimeMillis()) {
            epochMilli = System.currentTimeMillis();
        }
        this.startTimeStampMap = new ConcurrentHashMap<>();
        realTimerMap = new ConcurrentHashMap<>();
        for (KLineInterval lineInterval : kLineInterval) {
            this.startTimeStampMap.put(lineInterval, epochMilli);
            realTimerMap.put(lineInterval, epochMilli);
        }
        this.maxPrice = maxPrice;
        this.minPrice = minPrice;
    }

    protected KLine loadKLine(KLineInterval kLineInterval) throws Exception {

        double nextLow = minPrice + (maxPrice - minPrice) * random.nextDouble();
        double nextHigh = nextLow + (maxPrice - nextLow) * random.nextDouble();
        double nextOpen = nextLow + (nextHigh - nextLow) * random.nextDouble();
        double nextClose = nextLow + (nextHigh - nextLow) * random.nextDouble();

        double volume = 10 + (Double.MAX_VALUE / 2 - 10) * random.nextDouble();
        long plus = kLineInterval.getSecond() * 1000;
        long openTime = startTimeStampMap.get(kLineInterval);

        realTimerMap.computeIfPresent(kLineInterval, (k,v)->v + 200);
        long curTime = realTimerMap.get(kLineInterval);

        boolean isRealTime = curTime > System.currentTimeMillis() - kLineInterval.getSecond() * 1000;
        if (isRealTime) {
            if (curTime >= openTime + plus) {
                openTime += plus;
                startTimeStampMap.put(kLineInterval, openTime);
            }
        } else {
            openTime += plus;
            startTimeStampMap.put(kLineInterval, openTime);
        }


        KLine kLine = new KLine(symbol, nextOpen, nextClose, nextHigh, nextLow, volume, openTime,
                openTime + plus - 1000, !isRealTime, kLineInterval, new IndicatorMap());
        return kLine;
    }

    @Override
    protected void onOpen(Configuration parameters) throws Exception {
        executorService = Executors.newVirtualThreadPerTaskExecutor();
    }

    @Override
    protected void loadDataInBuffer(BlockingQueue<KLine> buffer) {
        for (KLineInterval interval : intervals) {
            CompletableFuture.runAsync(()->{
                while (true) {
                    try {
                        TimeUnit.MILLISECONDS.sleep(200);
                    } catch (InterruptedException e) {
                        throw new RuntimeException(e);
                    }
                    try {
                        buffer.put(loadKLine(interval));
                    } catch (Exception e) {
                        throw new RuntimeException(e);
                    }
                }
            }, executorService);
        }
    }

}

package com.helei.tradesignalcenter.stream.a_klinesource.impl;

import cn.hutool.core.collection.ConcurrentHashSet;
import com.helei.binanceapi.BinanceWSApiClient;
import com.helei.binanceapi.api.rest.BinanceUContractMarketRestApi;
import com.helei.binanceapi.config.BinanceApiConfig;
import com.helei.cexapi.CEXApiFactory;
import com.helei.constants.KLineInterval;
import com.helei.constants.TradeType;
import com.helei.dto.KLine;
import com.helei.tradesignalcenter.constants.RunEnv;
import com.helei.tradesignalcenter.stream.a_datasource.HistoryKLineLoader;
import com.helei.tradesignalcenter.stream.a_klinesource.KLineHisAndRTSource;
import com.helei.tradesignalcenter.stream.a_klinesource.KafkaRealTimeSourceFactory;
import lombok.extern.slf4j.Slf4j;
import org.apache.flink.configuration.Configuration;
import org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.KafkaConsumer;
import org.jetbrains.annotations.NotNull;

import javax.net.ssl.SSLException;
import java.net.URISyntaxException;
import java.time.Duration;
import java.time.Instant;
import java.util.Set;
import java.util.concurrent.*;


/**
 * 币安历史k线和实时k线Flink数据源
 * <p>一个BinanceKLineHisAndReTSource代表一个交易对（symbol）下的k线数据源， 可以有不同的KLineInterval</p>
 * <p>1.先根据startTime获取历史数据，历史数据获取完毕后才向flink source 中加入实时的数据</p>
 * <p>2.实时数据在启动时就通过KafkaConsumer开始统一获取，只是要等到历史数据获取完毕才写入flink source</p>
 */
@Slf4j
public class BinanceKLineHisAndRTSource extends KLineHisAndRTSource {

    /**
     * 相关回调执行的线程池
     */
    private transient ExecutorService executor;

    /**
     * 已加载完毕的历史k线
     */
    private transient ConcurrentHashSet<KLineInterval> historyLoadedIntervals;

    /**
     * binance api config
     */
    private final BinanceApiConfig binanceApiConfig;


    protected BinanceKLineHisAndRTSource(
            String symbol,
            Set<KLineInterval> kLineIntervals,
            long startTime
    ) {
        super(symbol, kLineIntervals, startTime);
        this.binanceApiConfig = BinanceApiConfig.INSTANCE;
    }

    @Override
    public void onOpen(Configuration parameters) throws Exception {
        historyLoadedIntervals = new ConcurrentHashSet<>();
        executor = Executors.newVirtualThreadPerTaskExecutor();
    }

    @Override
    public void loadDataInBuffer(BlockingQueue<KLine> buffer) {

        int batchSize = tradeSignalConfig.getHistoryKLineBatchSize();
        TradeType tradeType = tradeSignalConfig.getTrade_type();
        Instant startInstant = Instant.ofEpochMilli(startTime);


        //Step 1: 初始化HistoryKLineLoader
        HistoryKLineLoader historyKLineLoader = initHistoryKLineLoader(tradeType, batchSize, executor);

        //Step 2: 遍历k线频率列表，开始加载历史k线数据
        for (KLineInterval interval : intervals) {
            CompletableFuture
                    .supplyAsync(() -> {
                        //Step 2.1: 获取历史k线，写入sourceContext
                        log.info("开始获取历史k线数据, symbol[{}], interval[{}], startTime[{}]",
                                symbol, interval, startInstant);

                        CompletableFuture<Long> future = historyKLineLoader.startLoad(symbol, interval, startTime, kLines -> {
                            log.info("获取到历史k线批数据 [{}]-[{}]: {}", symbol, interval, kLines.size());
                            for (KLine kLine : kLines) {
                                kLine.setSymbol(symbol);
                                buffer.add(kLine);
                            }
                        });
                        try {
                            future.get();
                            log.info("symbol[{}], interval[{}]历史k线数据获取完毕", symbol, interval);
                        } catch (InterruptedException | ExecutionException e) {
                            log.error("加载历史k线数据出错", e);
                            System.exit(-1);
                        }
                        return interval;
                    }, executor)
                    .thenAcceptAsync(itv -> {
                        //Step 2.2: 历史k线获取完毕后记录状态
                        historyLoadedIntervals.add(itv);

                        if (historyLoadedIntervals.size() == intervals.size()) {
                            //所有历史k线获取完毕，关闭客户端
                            log.info("所有历史k线获取完毕");
                            historyKLineLoader.closeClient();
                        }
                    }, executor)
                    .exceptionally(e -> {
                        log.error("异步任务执行异常", e);
                        return null;
                    });
        }


        //Step 3: 获取实时k线，写入buffer
        CompletableFuture.runAsync(()->{
            KafkaRealTimeSourceFactory sourceFactory = new KafkaRealTimeSourceFactory(symbol, intervals);

            KafkaConsumer<String, KLine> rtConsumer = sourceFactory
                    .loadRTKLineStream(BinanceApiConfig.cexType, tradeType);
            while (isRunning) {
                ConsumerRecords<String, KLine> records = rtConsumer.poll(Duration.ofMillis(100));
                for (ConsumerRecord<String, KLine> record : records) {
                    KLine kline = record.value();
                    // 只有当历史k线数据加载完毕，才会向写入buffer中加入实时数据
                    KLineInterval kLineInterval = kline.getKLineInterval();
                    if ((kLineInterval != null && historyLoadedIntervals.contains(kLineInterval))) {
                        buffer.add(kline);
                    }
                }
            }
        }, executor).exceptionally(e -> {
            log.error("加载实时数据出错", e);
            return null;
        });
    }

    /**
     * 初始化历史k线加载器
     * @param tradeType tradeType
     * @param batchSize batchSize
     * @param executor executor
     * @return HistoryKLineLoader
     */
    @NotNull
    private HistoryKLineLoader initHistoryKLineLoader(
            TradeType tradeType,
            int batchSize,
            ExecutorService executor
    ) {
        String historyApiUrl = getHistoryApiUrl(tradeType);

        HistoryKLineLoader historyKLineLoader;
        log.info("开始初始化历史k线获取客户端, api url[{}]，RunEnv[{}], tradeType[{}]", historyApiUrl, tradeSignalConfig.getRun_env(), tradeType);
        try {
            historyKLineLoader = switch (tradeType) {
                case SPOT -> spotHistoryKLineLoader(historyApiUrl, batchSize, executor);
                case CONTRACT -> contractHistoryKLineLoader(historyApiUrl, batchSize, executor);
            };
        } catch (Exception e) {
            log.error("获取历史k线信息失败，api url [{}]", historyApiUrl, e);
            throw new RuntimeException("获取历史k线信息失败", e);
        }
        return historyKLineLoader;
    }

    /**
     * 获取现货历史k线数据加载器
     * @param historyApiUrl historyApiUrl
     * @param batchSize batchSize
     * @param executor executor
     * @return HistoryKLineLoader
     */
    @NotNull
    private HistoryKLineLoader spotHistoryKLineLoader(String historyApiUrl, int batchSize, ExecutorService executor) throws URISyntaxException, SSLException, InterruptedException, ExecutionException {
        BinanceWSApiClient apiClient = CEXApiFactory.binanceApiClient(historyApiUrl, "binance-history-kline-client");
        apiClient.connect().get();
        return new HistoryKLineLoader(batchSize, apiClient, executor);
    }


    /**
     * 获取合约历史k线数据加载器
     * <p>由于合约币安没提供k线数据的websocket的获取方式，所以用的rest api</p>
     * @param historyApiUrl historyApiUrl
     * @param batchSize batchSize
     * @param executor executor
     * @return HistoryKLineLoader
     */
    @NotNull
    private HistoryKLineLoader contractHistoryKLineLoader(String historyApiUrl, int batchSize, ExecutorService executor) {
        BinanceUContractMarketRestApi binanceUContractMarketRestApi = CEXApiFactory.binanceUContractMarketRestApi(historyApiUrl, executor);
        return new HistoryKLineLoader(batchSize, binanceUContractMarketRestApi, executor);
    }



    /**
     * 获取请求历史数据的api url
     *
     * @return url
     */
    protected String getHistoryApiUrl(TradeType tradeType) {
        if (RunEnv.NORMAL.equals(tradeSignalConfig.getRun_env())) {
            return switch (tradeType) {
                case SPOT -> binanceApiConfig.getNormal().getSpot().getWs_market_url();
                case CONTRACT -> binanceApiConfig.getNormal().getU_contract().getRest_api_url();
            };
        } else {
            return switch (tradeType) {
                case SPOT -> binanceApiConfig.getTest_net().getSpot().getWs_market_url();
                case CONTRACT -> binanceApiConfig.getTest_net().getU_contract().getRest_api_url();
            };
        }
    }
}


package com.helei.tradesignalcenter.stream.a_klinesource;

import com.helei.constants.CEXType;
import com.helei.constants.KLineInterval;
import com.helei.constants.TradeType;
import com.helei.dto.KLine;
import com.helei.tradesignalcenter.config.TradeSignalConfig;
import com.helei.util.KafkaUtil;
import lombok.extern.slf4j.Slf4j;
import org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.KafkaConsumer;

import java.util.List;
import java.util.Properties;
import java.util.Set;


/**
 * kafka实时数据源
 * <p>
 * 1.获取实时k线数据，一个KafkaRealTimeKLineSource对象代表一种k线（相同的symbol和interval）
 * </p>
 */
@Slf4j
public class KafkaRealTimeSourceFactory {


    /**
     * 交易对
     */
    private final String symbol;

    /**
     * k线频率
     */
    private final Set<KLineInterval> intervals;

    /**
     * 实时kafka设置
     */
    private final TradeSignalConfig.RealtimeKafkaConfig realtimeKafkaConfig;


    public KafkaRealTimeSourceFactory(
            String symbol,
            Set<KLineInterval> intervals
    ) {
        this.symbol = symbol;
        this.intervals = intervals;
        realtimeKafkaConfig = TradeSignalConfig.TRADE_SIGNAL_CONFIG.getRealtime().getKafka();
    }

    /**
     * 创建实时k线数据源
     *
     * @param cexType cexType
     * @param tradeType tradeType
     */
    public KafkaConsumer<String, KLine> loadRTKLineStream(
            CEXType cexType,
            TradeType tradeType
    ) {
        List<String> topicList = intervals
                .stream()
                .map(interval -> KafkaUtil.resolveKafkaTopic(cexType, KafkaUtil.getKLineStreamName(symbol, interval), tradeType))
                .toList();

        String bootstrapServer = realtimeKafkaConfig.getInput().getBootstrapServer();
        String groupId = realtimeKafkaConfig.getInput().getGroupId();

        Properties properties = new Properties();
        properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServer);
        properties.setProperty(ConsumerConfig.GROUP_ID_CONFIG, groupId);
        properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, "com.helei.tradesignalcenter.serialization.KafkaKLineSchema");
        properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, "com.helei.tradesignalcenter.serialization.KafkaKLineSchema");

        KafkaConsumer<String, KLine> consumer = null;
        try {
            consumer = new KafkaConsumer<>(properties);
            consumer.subscribe(topicList);
            log.info("开始创建kafka kline数据流，kafka server[{}], groupId[{}], topics[{}] ",
                    bootstrapServer, groupId, topicList);
        } catch (Exception e) {
            log.error("创建kafka consumer失败,kafka server[{}], groupId[{}]", bootstrapServer, groupId);
            throw new RuntimeException("创建kafka consumer失败", e);
        }

        return consumer;
    }



}


package com.helei.tradesignalcenter.stream.b_indicator;

import com.helei.dto.KLine;
import com.helei.dto.indicator.Indicator;
import com.helei.tradesignalcenter.stream.b_indicator.calculater.BaseIndicatorCalculator;
import lombok.Getter;
import lombok.Setter;
import lombok.extern.slf4j.Slf4j;
import org.apache.flink.api.common.state.ValueState;
import org.apache.flink.configuration.Configuration;
import org.apache.flink.streaming.api.functions.KeyedProcessFunction;
import org.apache.flink.util.Collector;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

@Slf4j
@Getter
@Setter
public class IndicatorProcessFunction extends KeyedProcessFunction<String, KLine, KLine> {

    private transient ExecutorService executor;

    /**
     * 指标计算器
     */
    private final BaseIndicatorCalculator<? extends Indicator>[] indicatorCalList;

    private final int period = 15;

    private transient ValueState<Double> maState;

    public IndicatorProcessFunction(BaseIndicatorCalculator<? extends Indicator>[] indicatorCalList) {
        this.indicatorCalList = indicatorCalList;
    }

    @Override
    public void open(Configuration parameters) throws Exception {
        executor = Executors.newVirtualThreadPerTaskExecutor();
        for (BaseIndicatorCalculator<?> calculator : indicatorCalList) {
            calculator.open(parameters, getRuntimeContext());
        }

//        this.maState = getRuntimeContext().getState(new ValueStateDescriptor<>("maState", Double.class));
    }

    @Override
    public void processElement(KLine kLine, KeyedProcessFunction<String, KLine, KLine>.Context context, Collector<KLine> collector) throws Exception {
        List<CompletableFuture<?>> futures = new ArrayList<>();

        for (BaseIndicatorCalculator<? extends Indicator> calculator : indicatorCalList) {

            CompletableFuture<?> future = CompletableFuture.runAsync(() -> {
                try {
                    Indicator indicator = calculator.calculateInKLine(kLine);
                    if (indicator != null) {
                        kLine.getIndicators().put(calculator.getIndicatorConfig(), indicator);
                    }
                } catch (Exception e) {
                    log.error("计算指标[{}]发生错误", calculator.getIndicatorConfig().getIndicatorName(), e);
                }
            }, executor);
            futures.add(future);
        }

        futures.forEach(CompletableFuture::join);
        collector.collect(kLine);
    }
}

package com.helei.tradesignalcenter.stream.c_signal.maker;

import cn.hutool.core.util.BooleanUtil;
import com.helei.dto.KLine;
import com.helei.dto.TradeSignal;
import lombok.extern.slf4j.Slf4j;
import org.apache.flink.api.common.functions.OpenContext;
import org.apache.flink.api.common.state.ValueState;
import org.apache.flink.api.common.state.ValueStateDescriptor;
import org.apache.flink.api.common.typeinfo.TypeHint;
import org.apache.flink.api.common.typeinfo.TypeInformation;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.streaming.api.TimerService;
import org.apache.flink.streaming.api.functions.KeyedProcessFunction;
import org.apache.flink.util.Collector;

import java.io.IOException;


/**
 * 信号生成器的抽象类，会把传入的KLine分为两类
 * 1. 已完结的k线数据， kLine.end = true
 * 这样的k线数据，可以认为是历史k线数据，可用于状态更新。
 * 2、实时的k线数据， kLine.end = false
 * 实时数据，用于决策是否产出信号
 */
@Slf4j
public abstract class AbstractSignalMaker extends KeyedProcessFunction<String, KLine, TradeSignal> {

    /**
     * 是否是一条k线只发出一个信号
     */
    private final boolean isAKLineSendOneSignal;


    /**
     * 时间基线， 第一个为收到第一个k或下一个k的openTime， 第二个为对应的processTime
     */
    protected ValueState<Tuple2<Long, Long>> timebaseState;

    /**
     * 当前k线，就是buildSignal(kline) 参数kline同意openTime的k线
     */
    protected ValueState<KLine> curKLine;

    /**
     * 前一条已完结的k线
     */
    protected ValueState<KLine> lastHistoryKLine;

    /**
     * 当前是否发出过信号
     */
    private ValueState<Boolean> isCurSendSignal;


    protected AbstractSignalMaker(boolean isAKLineSendOneSignal) {
        this.isAKLineSendOneSignal = isAKLineSendOneSignal;
    }

    @Override
    public void open(OpenContext openContext) throws Exception {
        timebaseState = getRuntimeContext().getState(new ValueStateDescriptor<>("timebaseState", TypeInformation.of(new TypeHint<Tuple2<Long, Long>>() {
        })));
        curKLine = getRuntimeContext().getState(new ValueStateDescriptor<>("currentKLine", TypeInformation.of(KLine.class)));
        lastHistoryKLine = getRuntimeContext().getState(new ValueStateDescriptor<>("lastHistoryKLine", TypeInformation.of(KLine.class)));
        isCurSendSignal = getRuntimeContext().getState(new ValueStateDescriptor<>("isCurSendSignal", Boolean.class));

        this.onOpen(openContext);
    }

    @Override
    public void processElement(KLine kLine, KeyedProcessFunction<String, KLine, TradeSignal>.Context context, Collector<TradeSignal> collector) throws Exception {

        //更新历史k，实时k
        updateCurKLine(kLine, context.timerService().currentProcessingTime());

        try {

            TradeSignal tradeSignal;

            if (BooleanUtil.isTrue(kLine.isEnd())) { //历史k线发出的信号打上标识
                tradeSignal = resolveHistoryKLine(kLine, context.timerService());
            } else {
                tradeSignal = resolveRealTimeKLine(kLine, context.timerService());
            }
            if (tradeSignal == null) return;

            setSignalCreateTIme(tradeSignal, context.timerService().currentProcessingTime());

            tradeSignal.setKLine(kLine);

//            if (isAKLineSendOneSignal && BooleanUtil.isTrue(isCurSendSignal.value())) {
//                //当前k线发送过信号
//                log.debug("this kLine sent signal, cancel send this time");
//            } else {
//                isCurSendSignal.update(true);
            collector.collect(tradeSignal);

//                log.debug("signal maker send a signal: [{}]", tradeSignal);
//            }
        } catch (Exception e) {
            log.error("build signal error", e);
            throw new RuntimeException(e);
        }
    }


    @Override
    public void onTimer(long timestamp, KeyedProcessFunction<String, KLine, TradeSignal>.OnTimerContext ctx, Collector<TradeSignal> out) throws Exception {
        TradeSignal tradeSignal = onTimerInvoke();
        if (tradeSignal != null) {
            log.info("signal maker send a timer signal: [{}]", tradeSignal);

            tradeSignal.setCreateTime(tradeSignal.getKLine().isEnd() ? tradeSignal.getKLine().getCloseTime() : ctx.timerService().currentProcessingTime());
            out.collect(tradeSignal);
        }
    }


    /**
     * onOpen.定义state的初始化等
     *
     * @param openContext openContext
     * @throws Exception Exception
     */
    public abstract void onOpen(OpenContext openContext) throws Exception;


    /**
     * 更新状态，传入的k线是已完结的k线数据
     *
     * @param kLine        已完结的k线数据
     * @param timerService timerService
     */
    protected abstract TradeSignal resolveHistoryKLine(KLine kLine, TimerService timerService) throws Exception;

    /**
     * 产生信号
     *
     * @param kLine        实时推送的k线数据
     * @param timerService timerService
     * @return 交易信号
     */
    protected abstract TradeSignal resolveRealTimeKLine(KLine kLine, TimerService timerService) throws Exception;


    /**
     * 产出定时信号，要触发，先要调用 context.timerService().registerProcessingTimeTimer(timer);
     *
     * @return TradeSignal
     * @throws IOException IOException
     */
    protected TradeSignal onTimerInvoke() throws Exception {
        return null;
    }

    /**
     * 更新当前k线，如果成功更新，还要将isSendSignal设置为false
     *
     * @param cur cur
     * @throws IOException IOException
     */
    private void updateCurKLine(KLine cur, long currentTime) throws IOException {
        Tuple2<Long, Long> timebase = timebaseState.value();

        if (timebase == null || cur.isEnd()) {
            timebase = new Tuple2<>(cur.getOpenTime(), currentTime);
        }
        timebaseState.update(timebase);

        KLine last = curKLine.value();
        //存储的k线为空，或存储的k线的open时间与收到的open时间不同。说明当前k线发生变化，重置状态
        if (last == null || last.getCloseTime() < cur.getOpenTime()) {
            isCurSendSignal.update(false);
        }
        if (cur.isEnd()) {
            lastHistoryKLine.update(cur);
        }

        curKLine.update(cur);
    }

    /**
     * 设置信号的创建时间
     *
     * @param currentTime 当前时间
     * @return 创建时间
     */
    public long setSignalCreateTIme(TradeSignal tradeSignal, long currentTime) throws IOException {
        Tuple2<Long, Long> timebase = timebaseState.value();
        if (timebase == null) {
            log.error("获取timebase错误，当前timebase不应为null");
            return -1;
        }
        long createTime = (long) timebase.getField(0) + (currentTime - (long) timebase.getField(1));
        //设置创建时间, 历史k线得到的信号，时间为这个k的结束时间
        tradeSignal.setCreateTime(createTime);

        return createTime;
    }
}
package com.helei.tradesignalcenter.stream.c_signal;

import com.helei.constants.KLineInterval;
import com.helei.dto.KLine;
import com.helei.dto.SignalGroupKey;
import com.helei.dto.TradeSignal;
import lombok.extern.slf4j.Slf4j;
import org.apache.flink.api.common.state.*;
import org.apache.flink.api.common.typeinfo.BasicTypeInfo;
import org.apache.flink.api.common.typeinfo.TypeHint;
import org.apache.flink.api.common.typeinfo.TypeInformation;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.configuration.Configuration;
import org.apache.flink.streaming.api.functions.co.KeyedCoProcessFunction;
import org.apache.flink.util.Collector;

import java.io.IOException;
import java.util.*;


/**
 * 信号分片器，将信号按照K线进行分组
 */
@Slf4j
public class SignalSplitResolver extends KeyedCoProcessFunction<String, KLine, TradeSignal, Tuple2<SignalGroupKey, List<TradeSignal>>> {

    /**
     * 发送窗口占k线的比例
     */
    private final double groupWindowRatioOfKLine;

    /**
     * 存储当前收到的信号
     */
    private ListState<TradeSignal> timebaseSignalListState;

    /**
     * 时间基线
     * index=0，为作为时间基线的k线的openTime
     * index=1，为创建这个基线时的系统ProcessTime
     */
    private ValueState<Tuple2<Long, Long>> timebaseState;

    /**
     * 发送窗口的开始时间
     */
    private ValueState<Long> sendWindowStartState;

    /**
     * 当前窗口的开始时间
     */
    private ValueState<Long> windowStartState;

    /**
     * 窗口长度
     */
    private ValueState<Long> windowLengthState;

    public SignalSplitResolver(double groupWindowRatioOfKLine) {
        this.groupWindowRatioOfKLine = groupWindowRatioOfKLine;
    }


    @Override
    public void open(Configuration parameters) throws Exception {
        timebaseSignalListState = getRuntimeContext().getListState(new ListStateDescriptor<>("timebaseSignalListState", TypeInformation.of(TradeSignal.class)));
        timebaseState = getRuntimeContext().getState(new ValueStateDescriptor<>("timebaseState", TypeInformation.of(new TypeHint<>() {})));
        sendWindowStartState = getRuntimeContext().getState(new ValueStateDescriptor<>("sendWindowStartState", BasicTypeInfo.LONG_TYPE_INFO));
        windowStartState = getRuntimeContext().getState(new ValueStateDescriptor<>("windowStartState", BasicTypeInfo.LONG_TYPE_INFO));
        windowLengthState = getRuntimeContext().getState(new ValueStateDescriptor<>("windowLengthState", BasicTypeInfo.LONG_TYPE_INFO));
    }


    @Override
    public void processElement1(KLine kLine, KeyedCoProcessFunction<String, KLine, TradeSignal, Tuple2<SignalGroupKey, List<TradeSignal>>>.Context context, Collector<Tuple2<SignalGroupKey, List<TradeSignal>>> collector) throws Exception {

        long startTime = getWindowStart(kLine, context.timerService().currentProcessingTime());


        //获取发送时间窗口内的信号
        List<TradeSignal> signalList = getOrInitSignalListState();

        List<TradeSignal> needSendSignal = new ArrayList<>();


        Long sendWindowStart = sendWindowStartState.value();
        if (sendWindowStart != null) {
            for (TradeSignal signal : signalList) {//当前k在基线时间内有信号
                //只添加在当前发送窗口的
                if (signal.getCreateTime() >= sendWindowStart && signal.getCreateTime() <= sendWindowStart + windowLengthState.value()) {
                    needSendSignal.add(signal);
                }
            }
        }

        SignalGroupKey signalGroupKey = new SignalGroupKey(kLine.getSymbol(), kLine.getKLineInterval());
        //发送流
        collector.collect(new Tuple2<>(signalGroupKey, needSendSignal));

        //更新发送窗口
        updateSignalListState(signalList, startTime);
    }


    @Override
    public void processElement2(TradeSignal signal, KeyedCoProcessFunction<String, KLine, TradeSignal, Tuple2<SignalGroupKey, List<TradeSignal>>>.Context context, Collector<Tuple2<SignalGroupKey, List<TradeSignal>>> collector) throws Exception {
        List<TradeSignal> signalList = getOrInitSignalListState();
        if (signal.getCreateTime() == null) {
            log.warn("信号没有创建时间，将自动丢弃.[{}]", signal);
            return;
        }
        signalList.add(signal);
        timebaseSignalListState.update(signalList);
    }


    /**
     * 获取当前窗口的起始时间
     *
     * @param kLine       kLine
     * @param currentTime currentTime
     * @return 当前窗口的起始位置
     * @throws IOException IOException
     */
    private Long getWindowStart(KLine kLine, long currentTime) throws IOException {
        //1. 获取窗口长度
        Long sendWindowLength = windowLengthState.value();
        if (sendWindowLength == null) {
            sendWindowLength = (long) (kLine.getKLineInterval().getSecond() * groupWindowRatioOfKLine * 1000);
            windowLengthState.update(sendWindowLength);
        }

        //2. 获取时间基线，当前K线open时间和当前时间
        Tuple2<Long, Long> timebase = timebaseState.value();
        if (timebase == null || kLine.isEnd()) {
            timebase = new Tuple2<>(kLine.getOpenTime(), currentTime);
        }
        timebaseState.update(timebase);

        //3. 确定窗口的开始和发送窗口的开始
        Long lastWindowStart = windowStartState.value();
        Long windowStart = (Long) timebase.getField(0) + (currentTime - (Long) timebase.getField(1)) / sendWindowLength * sendWindowLength;
        windowStartState.update(windowStart);

        if (lastWindowStart == null) {
            lastWindowStart = windowStart;
        }

        //4.根据窗口其实位置是否发生变化，设置是否能够发送信号的状态
        if (!windowStart.equals(lastWindowStart)) {
            sendWindowStartState.update(lastWindowStart);
        } else {
            sendWindowStartState.update(null);
        }

        return windowStart;
    }

    /**
     * 更新窗口，去除过期的
     *
     * @param signalList signalList
     * @param limitTime  limitTime
     * @throws Exception Exception
     */
    private void updateSignalListState(List<TradeSignal> signalList, Long limitTime) throws Exception {
        signalList.removeIf(signal -> signal.getCreateTime() < limitTime);
        timebaseSignalListState.update(signalList);
    }


    /**
     * 取SignalList，如果为空则会初始化
     *
     * @return SignalList
     * @throws Exception SignalList
     */
    private List<TradeSignal> getOrInitSignalListState() throws Exception {
        List<TradeSignal> signals = new ArrayList<>();
        Iterable<TradeSignal> iterable = timebaseSignalListState.get();

        if (iterable == null) {
            timebaseSignalListState.update(signals);
            return signals;
        }

        iterable.forEach(signals::add);
        signals.sort(Comparator.comparing(TradeSignal::getCreateTime));
        return signals;
    }
}


package com.helei.tradesignalcenter.stream.c_signal;

import com.helei.dto.SignalGroupKey;
import com.helei.dto.indicator.Indicator;
import com.helei.dto.KLine;
import com.helei.dto.TradeSignal;
import com.helei.tradesignalcenter.stream.a_klinesource.KLineHisAndRTSource;
import com.helei.tradesignalcenter.stream.b_indicator.IndicatorProcessFunction;
import com.helei.tradesignalcenter.stream.b_indicator.calculater.BaseIndicatorCalculator;
import com.helei.tradesignalcenter.stream.c_signal.maker.AbstractSignalMaker;
import lombok.Getter;
import lombok.extern.slf4j.Slf4j;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.datastream.KeyedStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;

import java.util.*;
import java.util.function.Function;


@Slf4j
@Getter
public class TradeSignalService {
    /**
     * 环境
     */
    private final StreamExecutionEnvironment env;

    /**
     * 信号生成器
     */
    private final List<TradeSignalStreamResolver> resolverList;


    public TradeSignalService(StreamExecutionEnvironment env) {
        this.env = env;
        this.resolverList = new ArrayList<>();
    }


    public static TradeSignalServiceBuilder builder(StreamExecutionEnvironment env) {
        return new TradeSignalServiceBuilder(new TradeSignalService(env));
    }


    /**
     * 添加信号流处理器
     *
     * @param resolver resolver
     */
    public void addTradeSignalStreamResolver(TradeSignalStreamResolver resolver) {
        this.resolverList.add(resolver);
    }


    /**
     * 当前信号流处理器是否为空
     *
     * @return boolean
     */
    public boolean isEmpty() {
        return resolverList.isEmpty();
    }


    /**
     * 获取联合的交易信号流，，根据交易对名symbol进行的keyby
     *
     * @return KeyedStream
     */
    public KeyedStream<Tuple2<SignalGroupKey, List<TradeSignal>>, String> getSymbolGroupSignalStream() {
        if (resolverList.isEmpty()) {
            log.error("没有添加信号流处理器");
            throw new IllegalArgumentException("没有添加信号流处理器");
        }

        DataStream<Tuple2<SignalGroupKey, List<TradeSignal>>> combineStream = resolverList.getFirst().makeSignalStream();
        for (int i = 1; i < resolverList.size(); i++) {
            combineStream.union(resolverList.get(i).makeSignalStream());
        }

        return combineStream.keyBy(t2 -> {
            SignalGroupKey k = t2.getField(0);
            return k.getSymbol();
        });
    }

    /**
     * 交易信号流处理器
     */
    @Getter
    public static class TradeSignalStreamResolver {
        /**
         * 环境
         */
        private final StreamExecutionEnvironment env;

        /**
         * k线数据源
         */
        private KLineHisAndRTSource kLineSource;

        /**
         * 指标计算器
         */
        private final List<BaseIndicatorCalculator<? extends Indicator>> indicatorCalList;

        /**
         * 信号处理器
         */
        private final List<AbstractSignalMaker> signalMakers;

        /**
         * 分组窗口占k线时间区间的比例
         */
        private double groupWindowRatioOfKLine = 0.2;


        public TradeSignalStreamResolver(StreamExecutionEnvironment env) {
            this.env = env;

            this.indicatorCalList = new ArrayList<>();

            this.signalMakers = new ArrayList<>();
        }


        /**
         * 开始执行产生信号流
         *
         * @return 信号流
         */
        public DataStream<Tuple2<SignalGroupKey, List<TradeSignal>>> makeSignalStream() {
            if (kLineSource == null) {
                throw new IllegalArgumentException("未添加k线数据源");
            }

            //1. 使用自定义 SourceFunction 生成 K 线数据流
            KeyedStream<KLine, String> kLineStream = env
                    .addSource(kLineSource)
                    .keyBy(KLine::getStreamKey);

//            kLineStream.print();

            BaseIndicatorCalculator<?>[] arr = new BaseIndicatorCalculator[indicatorCalList.size()];
            for (int i = 0; i < indicatorCalList.size(); i++) {
                arr[i] = indicatorCalList.get(i);
            }
            // 2.指标处理，串行
            kLineStream = kLineStream
                    .process(new IndicatorProcessFunction(arr))
                    .setParallelism(1)
                    .keyBy(KLine::getStreamKey);

//            kLineStream.print();

            if (signalMakers.isEmpty()) {
                throw new IllegalArgumentException("没有信号生成器");
            }

//            //3, 信号处理,并行
            Iterator<AbstractSignalMaker> signalMakerIterator = signalMakers.iterator();

            DataStream<TradeSignal> signalStream = kLineStream.process(signalMakerIterator.next());

            while (signalMakerIterator.hasNext()) {

                signalStream = signalStream.union(kLineStream.process(signalMakerIterator.next()));
            }


            return groupSignalStreamBySymbol(kLineStream, signalStream);
        }


        /**
         * 根据kline中已完结k线，将signal按照k线进行分组
         *
         * @param kLineStream  kLineStream
         * @param signalStream signalStream
         * @return 按照k线分组的信号
         */
        private DataStream<Tuple2<SignalGroupKey, List<TradeSignal>>> groupSignalStreamBySymbol(KeyedStream<KLine, String> kLineStream, DataStream<TradeSignal> signalStream) {

//            signalStream.print();
            return kLineStream
                    .connect(signalStream.keyBy(TradeSignal::getKlineStreamKey))
                    .process(new SignalSplitResolver(groupWindowRatioOfKLine));
        }
    }

    public static class TradeSignalServiceBuilder {

        private final TradeSignalService tradeSignalService;

        public TradeSignalServiceBuilder(TradeSignalService tradeSignalService) {
            this.tradeSignalService = tradeSignalService;
        }

        public TradeSignalStreamResolverBuilder buildResolver() {
            return new TradeSignalStreamResolverBuilder(tradeSignalService.getEnv(), resolver -> {
                tradeSignalService.addTradeSignalStreamResolver(resolver);
                return this;
            });
        }


        public TradeSignalService build() {
            return tradeSignalService;
        }
    }

    public static class TradeSignalStreamResolverBuilder {

        private final TradeSignalStreamResolver tradeSignalStreamResolver;

        private final Function<TradeSignalStreamResolver, TradeSignalServiceBuilder> addInService;


        TradeSignalStreamResolverBuilder(StreamExecutionEnvironment env, Function<TradeSignalStreamResolver, TradeSignalServiceBuilder> addInService) {
            this.tradeSignalStreamResolver = new TradeSignalStreamResolver(env);
            this.addInService = addInService;
        }


        /**
         * 设置数据源
         *
         * @param kLineSource 数据源
         * @return this
         */
        public TradeSignalStreamResolverBuilder addKLineSource(KLineHisAndRTSource kLineSource) {
            tradeSignalStreamResolver.kLineSource = kLineSource;
            return this;
        }


        /**
         * 设置分组窗口占k线的比例
         *
         * @param ratio ratio
         * @return this
         */
        public TradeSignalStreamResolverBuilder setWindowLengthRationOfKLine(double ratio) {
            tradeSignalStreamResolver.groupWindowRatioOfKLine = ratio;
            return this;
        }


        /**
         * 添加指标计算器
         *
         * @param calculator 指标计算器
         * @return this
         */
        public TradeSignalStreamResolverBuilder addIndicator(BaseIndicatorCalculator<? extends Indicator> calculator) {
            tradeSignalStreamResolver.getIndicatorCalList().add(calculator);
            return this;
        }

        /**
         * 添加信号生成器
         *
         * @param signalMaker 信号生成器
         * @return this
         */
        public TradeSignalStreamResolverBuilder addSignalMaker(AbstractSignalMaker signalMaker) {
            tradeSignalStreamResolver.getSignalMakers().add(signalMaker);
            return this;
        }

        public TradeSignalServiceBuilder addInService() {
            return addInService.apply(tradeSignalStreamResolver);
        }
    }
}


package com.helei.tradesignalcenter.stream.d_decision;


import com.helei.dto.IndicatorMap;
import com.helei.tradesignalcenter.dto.OriginOrder;
import com.helei.dto.TradeSignal;
import com.helei.tradesignalcenter.stream.d_decision.config.PSTBollDecisionConfig_v1;
import com.helei.dto.indicator.Indicator;
import com.helei.dto.indicator.config.IndicatorConfig;
import lombok.extern.slf4j.Slf4j;

import java.math.BigDecimal;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.stream.Collectors;

/**
 * 根据PST和Boll指标决策下单
 */
@Deprecated
@Slf4j
public class PSTBollDecisionMaker extends AbstractDecisionMaker<OriginOrder> {

    private final PSTBollDecisionConfig_v1 config;

    public PSTBollDecisionMaker(PSTBollDecisionConfig_v1 config) {
        super(config.getName());
        this.config = config;
    }

    @Override
    protected OriginOrder decisionAndBuilderOrder(String symbol, List<TradeSignal> windowSignal, IndicatorMap indicatorMap) {
        String pstKey = config.getPstConfig().getIndicatorName();
        String bollKey = config.getBollConfig().getIndicatorName();

        Map<String, List<TradeSignal>> signalMap = windowSignal.stream().collect(Collectors.groupingBy(TradeSignal::getName));

        List<TradeSignal> pstSignals = signalMap.get(pstKey);
        List<TradeSignal> bollSignals = signalMap.get(bollKey);

        if (pstSignals == null || bollSignals == null || pstSignals.isEmpty() || bollSignals.isEmpty()) {
            log.warn("pst和boll信号不满足共振， 不生成订单");
            return null;
        }

        TradeSignal newPstSignal = pstSignals.getLast();
        TradeSignal newBollSignal = bollSignals.getLast();

        //TODO 仅仅测试用
        return buildMarketOrder(newBollSignal);
    }

    private static OriginOrder buildMarketOrder(TradeSignal newBollSignal) {
        return OriginOrder
                .builder()
                .symbol(newBollSignal.getKLine().getSymbol())
                .tradeSide(newBollSignal.getTradeSide())
                .targetPrice(BigDecimal.valueOf(newBollSignal.getTargetPrice()))
                .stopPrice(BigDecimal.valueOf(newBollSignal.getStopPrice()))
                .build();
    }
}
package com.helei.tradesignalcenter.stream.e_order;

import com.helei.tradesignalcenter.config.TradeSignalConfig;
import com.helei.tradesignalcenter.dto.OriginOrder;
import com.helei.util.Serializer;
import lombok.extern.slf4j.Slf4j;
import org.apache.flink.api.common.serialization.SerializationSchema;
import org.apache.flink.api.connector.sink2.Sink;
import org.apache.flink.connector.base.DeliveryGuarantee;
import org.apache.flink.connector.kafka.sink.KafkaRecordSerializationSchema;
import org.apache.flink.connector.kafka.sink.KafkaSink;
import org.apache.kafka.clients.producer.ProducerConfig;

import java.util.Properties;


@Slf4j
public class KafkaOriginOrderCommitter extends AbstractOrderCommitter<OriginOrder>{


    @Override
    public Sink<OriginOrder> getCommitSink() {
        TradeSignalConfig.KafkaServerConfig kafkaServerConfig = tradeSignalConfig.getRealtime().getKafka().getOutput();
        String bootstrap = kafkaServerConfig.getBootstrapServer();
        String topic = tradeSignalConfig.getSinkTopic();

        log.info("创建 原始订单 Kafka Sink [{}] - topic [{}]", bootstrap, topic);

        Properties props = new Properties();
        props.setProperty(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG, kafkaServerConfig.getTransaction_timeout_ms());

        return KafkaSink.<OriginOrder>builder()
                .setBootstrapServers(bootstrap)
                .setRecordSerializer(
                        KafkaRecordSerializationSchema
                                .builder()
                                .setTopic(topic)
                                .setValueSerializationSchema(new KafkaOriginOrderSchema())
                                .build()
                )
//                .setDeliveryGuarantee(DeliveryGuarantee.EXACTLY_ONCE)
                .setKafkaProducerConfig(props)
                .build();
    }


    static class KafkaOriginOrderSchema implements SerializationSchema<OriginOrder> {
        @Override
        public byte[] serialize(OriginOrder originOrder) {
            return Serializer.Algorithm.Protostuff.serialize(originOrder);
        }
    }
}

package com.helei.tradesignalcenter.stream;

import com.helei.dto.KLine;
import com.helei.dto.SignalGroupKey;
import com.helei.dto.TradeSignal;
import com.helei.tradesignalcenter.stream.c_signal.TradeSignalService;
import com.helei.tradesignalcenter.stream.d_decision.AbstractDecisionMaker;
import com.helei.tradesignalcenter.stream.e_order.AbstractOrderCommitter;
import lombok.extern.slf4j.Slf4j;
import org.apache.flink.api.connector.sink2.Sink;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.datastream.KeyedStream;

import java.util.List;

@Slf4j
public class AutoTradeTask<T> {


    /**
     * 信号流服务
     */
    private final TradeSignalService tradeSignalService;

    /**
     * 决策服务
     */
    private final AbstractDecisionMaker<T> decisionMaker;

    /**
     * 订单提交器
     */
    private final AbstractOrderCommitter<T> orderCommitter;


    public AutoTradeTask(
            TradeSignalService tradeSignalService,
            AbstractDecisionMaker<T> decisionMaker,
            AbstractOrderCommitter<T> orderCommitter
    ) {
        this.tradeSignalService = tradeSignalService;

        this.decisionMaker = decisionMaker;

        this.orderCommitter = orderCommitter;
    }


    public void execute(String name) throws Exception {

        //1.信号服务
        KeyedStream<Tuple2<SignalGroupKey, List<TradeSignal>>, String> symbolGroupSignalStream = tradeSignalService.getSymbolGroupSignalStream();

        symbolGroupSignalStream.print();
        //2.决策服务
        DataStream<T> originOrderStream = symbolGroupSignalStream.process(decisionMaker);

        originOrderStream.print();
        //3订单提交服务
//        Sink<T> commitSink = orderCommitter.getCommitSink();
//        originOrderStream.sinkTo(commitSink);

        tradeSignalService.getEnv().execute(name);
    }

}



pipeline.serialization-config:
  - com.helei.dto.KLine :  {type: kryo, kryo-type: registered, class: com.helei.tradesignalcenter.serialization.KLineSerializer}
  - com.helei.dto.IndicatorMap: {type: kryo, kryo-type: registered, class: com.helei.tradesignalcenter.serialization.IndicatorMapSerializer}
  - com.helei.constants.KLineInterval: {type: kryo, kryo-type: registered, class: com.helei.tradesignalcenter.serialization.KLineIntervalSerializer}

shinano:
  quantity:
    # 信号生成服务配置
    trade_signal_maker:
      # name
      name: test
      # symbol
      symbol: btcusdt
      # 运行环境
      run_env: NORMAL
      # 交易类型
      trade_type: CONTRACT
      # 历史k线加载批大小
      historyKLineBatchSize: 200
      # 批加载的网络并发度
      batchLoadConcurrent: 10
      # 实时数据配置
      realtime:
        # kafka配置
        kafka:
          input:
            bootstrapServer: 192.168.1.2:9092
            groupId: trade_signal_app_test
            transaction_timeout_ms: 900000

          output:
            bootstrapServer: 127.0.0.1:9092
            groupId: trade_signal_app_test
            transaction_timeout_ms: 900000

        # flink配置
        flink:
          jobManagerHost: 192.168.1.2
          jobManagerPort: 8081


package com.helei.tradesignalcenter.stream.a_klinesource.impl;

import com.helei.constants.KLineInterval;
import com.helei.dto.KLine;
import com.helei.tradesignalcenter.config.FlinkConfig;
import org.apache.flink.api.common.functions.OpenContext;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.functions.ProcessFunction;
import org.apache.flink.util.Collector;
import org.junit.jupiter.api.BeforeAll;
import org.junit.jupiter.api.Test;

import java.time.LocalDateTime;
import java.time.ZoneOffset;
import java.util.Set;
import java.util.concurrent.TimeUnit;

class BinanceKLineHisAndRTSourceTest {

    private static StreamExecutionEnvironment env;

    private static String symbol = "btcusdt";


    @BeforeAll
    public static void setUpBeforeClass() throws Exception {
        env = FlinkConfig.streamExecutionEnvironment();
    }

    @Test
    public void testHisAndReTSource() throws Exception {
        BinanceKLineHisAndRTSource source = new BinanceKLineHisAndRTSource(
                symbol,
                Set.of(KLineInterval.m_1),
                LocalDateTime.of(2024, 10, 27, 21, 0).toInstant(ZoneOffset.UTC).toEpochMilli()
        );

        DataStream<KLine> stream = env.addSource(source);

        stream.process(new ProcessFunction<KLine, Object>() {
            @Override
            public void open(OpenContext openContext) throws Exception {
                super.open(openContext);
            }

            @Override
            public void processElement(KLine kLine, ProcessFunction<KLine, Object>.Context context, Collector<Object> collector) throws Exception {
//                if (BooleanUtil.isFalse(kLine.isEnd())) {
                    System.out.println(kLine);
//                }
            }
        }).setParallelism(1);

        env.execute();
        TimeUnit.MINUTES.sleep(300);
    }
}




package com.helei.tradesignalcenter.support;


import com.helei.constants.KLineInterval;
import com.helei.constants.TradeSide;
import com.helei.dto.IndicatorMap;
import com.helei.tradesignalcenter.config.FlinkConfig;
import com.helei.tradesignalcenter.stream.*;
import com.helei.tradesignalcenter.stream.a_datasource.RandomKLineSource;
import com.helei.tradesignalcenter.dto.OriginOrder;
import com.helei.dto.KLine;
import com.helei.dto.TradeSignal;
import com.helei.tradesignalcenter.stream.b_indicator.calculater.PSTCalculator;
import com.helei.tradesignalcenter.stream.c_signal.TradeSignalService;
import com.helei.tradesignalcenter.stream.c_signal.maker.PSTSignalMaker;
import com.helei.tradesignalcenter.stream.d_decision.AbstractDecisionMaker;
import com.helei.tradesignalcenter.stream.b_indicator.calculater.BollCalculator;
import com.helei.tradesignalcenter.stream.b_indicator.calculater.MACDCalculator;
import com.helei.dto.indicator.config.BollConfig;
import com.helei.dto.indicator.config.MACDConfig;
import com.helei.dto.indicator.config.PSTConfig;
import com.helei.tradesignalcenter.stream.c_signal.maker.AbstractSignalMaker;
import com.helei.tradesignalcenter.stream.c_signal.maker.BollSignalMaker;
import com.helei.tradesignalcenter.stream.e_order.AbstractOrderCommitter;
import com.helei.tradesignalcenter.stream.e_order.KafkaOriginOrderCommitter;
import org.apache.flink.api.common.functions.OpenContext;
import org.apache.flink.api.connector.sink2.Sink;
import org.apache.flink.streaming.api.TimerService;
import org.apache.flink.streaming.api.datastream.DataStreamSource;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.junit.jupiter.api.BeforeAll;
import org.junit.jupiter.api.Test;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.Serial;
import java.math.BigDecimal;
import java.time.LocalDateTime;
import java.util.List;
import java.util.Set;
import java.util.concurrent.TimeUnit;

public class RandomKLineSourceTest {
    private static final Logger log = LoggerFactory.getLogger(RandomKLineSourceTest.class);
    private static String btcusdt = "btcusdt";

    private static String ethusdt = "ethusdt";

    private static StreamExecutionEnvironment env;

    private static StreamExecutionEnvironment env2;


    private static RandomKLineSource randomKLineSource;


    @BeforeAll
    public static void before() {
        try {
            env = FlinkConfig.streamExecutionEnvironment();
            randomKLineSource = new RandomKLineSource(btcusdt, Set.of(KLineInterval.m_15),
                    LocalDateTime.of(2020, 10, 29, 15, 38), 2000.0, 19000.0);

        } catch (Exception e) {
            e.printStackTrace();
        }
    }

    @Test
    public void testRandomKLineSource() throws Exception {
        DataStreamSource<KLine> streamSource = env.addSource(randomKLineSource);

        streamSource.print();

        env.execute();
        TimeUnit.MINUTES.sleep(1000);
    }

    @Test
    public void testAutoTradeV2() throws Exception {
        PSTConfig pstConfig = new PSTConfig(60, 3, 3);
        BollConfig bollConfig = new BollConfig(15);


        TradeSignalService tradeSignalService = buildTradeSignalService(pstConfig, bollConfig);
        AbstractDecisionMaker<OriginOrder> abstractDecisionMaker = new AbstractDecisionMaker<>("测试用决策生成器") {
            @Serial
            private final static long serialVersionUID = 122142132145213L;

            @Override
            protected OriginOrder decisionAndBuilderOrder(String symbol, List<TradeSignal> windowSignal, IndicatorMap indicatorMap) {
                log.info("收到信号【{}】\n{}", symbol, windowSignal);
                return OriginOrder
                        .builder()
                        .symbol(symbol)
                        .tradeSide(TradeSide.BUY)
                        .targetPrice(BigDecimal.valueOf(windowSignal.getFirst().getTargetPrice()))
                        .stopPrice(BigDecimal.valueOf(windowSignal.getFirst().getStopPrice()))
                        .build();
            }
        };

        KafkaOriginOrderCommitter kafkaOriginOrderCommitter = new KafkaOriginOrderCommitter();


        AutoTradeTask<OriginOrder> autoTradeTask = new AutoTradeTask<OriginOrder>(
                tradeSignalService,
                abstractDecisionMaker,
                kafkaOriginOrderCommitter);

        autoTradeTask.execute("test");
    }

    private TradeSignalService buildTradeSignalService(PSTConfig pstConfig, BollConfig bollConfig) {
        return TradeSignalService
                .builder(env)
                .buildResolver()
                .setWindowLengthRationOfKLine(1.0 / 60)
                .addKLineSource(randomKLineSource)
                .addIndicator(new PSTCalculator(pstConfig))
//                .addIndicator(new MACDCalculator(new MACDConfig(12, 26, 9)))
                .addIndicator(new BollCalculator(bollConfig))
                .addSignalMaker(new BollSignalMaker(bollConfig))
//                .addSignalMaker(new PSTSignalMaker(pstConfig))
                .addSignalMaker(new AbstractSignalMaker(true) {

                    @Override
                    public void onOpen(OpenContext openContext) throws Exception {

                    }

                    @Override
                    protected TradeSignal resolveHistoryKLine(KLine kLine, TimerService timerService) throws Exception {
//                        System.out.println(Instant.ofEpochMilli(kLine.getOpenTime()) + " - " + kLine.getIndicators());
                        return TradeSignal.builder().description("这是一条测试信号1h").name("测试信号1h")
                                .kLine(kLine).tradeSide(TradeSide.BUY).targetPrice(1111111111.0).stopPrice(1231231.0).build();
                    }

                    @Override
                    protected TradeSignal resolveRealTimeKLine(KLine kLine, TimerService timerService) throws Exception {
                        return null;
                    }
                })
//                .addSignalMaker(new AbstractSignalMaker(true) {
//                    private Random random = new Random();
//
//                    @Override
//                    public void onOpen(OpenContext openContext) throws Exception {
//
//                    }
//
//                    @Override
//                    protected TradeSignal resolveHistoryKLine(KLine kLine, TimerService timerService) throws Exception {
//                        if (random.nextBoolean()) {
//                            return null;
//                        }
//                        return TradeSignal.builder().description("这是一条测试信号1h").name("测试信号1h").tradeSide(TradeSide.BUY).build();
//                    }
//
//                    @Override
//                    protected TradeSignal resolveRealTimeKLine(KLine kLine, TimerService timerService) throws Exception {
//                        if (random.nextBoolean()) {
//                            return null;
//                        }
//
//                        return TradeSignal.builder().description("这是一条测试信号1h").name("测试信号1h").tradeSide(TradeSide.BUY).build();
//                    }
//                })
                .addInService()
                .build();
    }

}

