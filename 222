package com.helei.reaktimedatacenter.service.impl.market;

import cn.hutool.core.collection.ListUtil;
import cn.hutool.core.lang.Pair;
import com.alibaba.fastjson.JSONObject;
import com.helei.binanceapi.base.SubscribeResultInvocationHandler;
import com.helei.binanceapi.config.BinanceApiConfig;
import com.helei.constants.CEXType;
import com.helei.constants.RunEnv;
import com.helei.constants.WebSocketStreamParamKey;
import com.helei.constants.trade.KLineInterval;
import com.helei.constants.trade.TradeType;
import com.helei.dto.base.KeyValue;
import com.helei.reaktimedatacenter.config.RealtimeConfig;
import com.helei.reaktimedatacenter.dto.SymbolKLineInfo;
import com.helei.reaktimedatacenter.service.MarketRealtimeDataService;
import com.helei.reaktimedatacenter.service.impl.KafkaProducerService;
import com.helei.util.KafkaUtil;
import lombok.extern.slf4j.Slf4j;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;


/**
 * 市场实时数据服务的抽象类
 * <P>能够将市场数据推送至kafka，会根据配置文件中的run_type来加载需要使用的环境。只需关注实现registryKLineDataLoader(*)方法</P>
 */
@Slf4j
public abstract class AbstractKafkaMarketRTDataService implements MarketRealtimeDataService {
    protected final ExecutorService taskExecutor;

    public final KafkaProducerService kafkaProducerService;

    protected final RealtimeConfig realtimeConfig;

    protected final BinanceApiConfig binanceApiConfig;

    public AbstractKafkaMarketRTDataService(ExecutorService taskExecutor, KafkaProducerService kafkaProducerService) {
        this.taskExecutor = taskExecutor;
        this.kafkaProducerService = kafkaProducerService;
        this.realtimeConfig = RealtimeConfig.INSTANCE;
        this.binanceApiConfig = BinanceApiConfig.INSTANCE;
    }

    @Override
    public Integer startSyncRealTimeKLine() {
        int all = 0;
        List<CompletableFuture<Integer>> futures = new ArrayList<>();

        for (KeyValue<RunEnv, TradeType> keyValue : realtimeConfig.getRun_type().getRunTypeList()) {
            futures.add(CompletableFuture.supplyAsync(() -> startSyncRealTimeKLine(keyValue.getKey(), keyValue.getValue()), taskExecutor));
        }

        for (CompletableFuture<Integer> future : futures) {
            try {
                all += future.get();
            } catch (InterruptedException | ExecutionException e) {
                throw new RuntimeException(e);
            }
        }
        return all;
    }

    @Override
    public Integer startSyncRealTimeKLine(RunEnv runEnv, TradeType tradeType) {
        log.info("开始同步env[{}]-tradeType[{}]的实时k线", runEnv, tradeType);

        RealtimeConfig.RealtimeKLineDataConfig realtimeKLineDataConfig = realtimeConfig.getEnvKLineDataConfig(runEnv, tradeType);

        //Step 1: 解析k线
        List<SymbolKLineInfo> realtimeKLineList = realtimeKLineDataConfig.getRealtimeKLineList();

        if (realtimeKLineList == null || realtimeKLineList.isEmpty()) {
            log.warn("runEnv[{}]-tradeType[{}] 没有设置要实时获取的k线", runEnv, tradeType);
            return 0;
        }

        List<Pair<String, KLineInterval>> intervals = new ArrayList<>();

        for (SymbolKLineInfo symbolKLineInfo : realtimeKLineList) {
            symbolKLineInfo.getIntervals().forEach(interval -> {
                intervals.add(new Pair<>(symbolKLineInfo.getSymbol(), interval));
            });
        }

        //Step 2: 创建topic
        log.info("开始检查并创建所需topic");
        createTopic(intervals, runEnv, tradeType);
        log.info("topic创建完毕");


        //Step 3: 分片执行
        List<List<Pair<String, KLineInterval>>> partition = ListUtil.partition(intervals, realtimeKLineDataConfig.getClient_listen_kline_max_count());


        try {
            List<CompletableFuture<Void>> futures = new ArrayList<>();
            for (List<Pair<String, KLineInterval>> list : partition) {

                //Step 4: 创建task执行获取
                CompletableFuture<Void> future = registryKLineDataLoader(
                        runEnv,
                        tradeType,
                        list,
                        (s, p, k) -> klineDataSyncToKafka(s, (KLineInterval) p.get(WebSocketStreamParamKey.KLINE_INTERVAL), k, runEnv, tradeType),
                        taskExecutor);

                futures.add(future);
            }

            CompletableFuture
                    .allOf(futures.toArray(new CompletableFuture[0]))
                    .get();

            log.info("所有k线开始实时同步");
        } catch (Exception e) {
            throw new RuntimeException(e);
        }

        return realtimeKLineList.size();
    }


    /**
     * 注册k线数据加载器
     *
     * @param runEnv               运行环境
     * @param tradeType            交易类型
     * @param listenKLines         k线
     * @param whenReceiveKLineData 回调，需要在whenReceiveKLineData.invoke()时传入symbol、interval、json格式的k线数据
     * @param executorService      执行的线程池
     * @return CompletableFuture
     */
    protected abstract CompletableFuture<Void> registryKLineDataLoader(
            RunEnv runEnv,
            TradeType tradeType,
            List<Pair<String, KLineInterval>> listenKLines,
            SubscribeResultInvocationHandler whenReceiveKLineData,
            ExecutorService executorService
    ) throws ExecutionException, InterruptedException;

    /**
     * 把k线发到kafka
     *
     * @param symbol symbol
     * @param data   data
     */
    public void klineDataSyncToKafka(String symbol, KLineInterval kLineInterval, JSONObject data, RunEnv runEnv, TradeType tradeType) {
        String topic = KafkaUtil.resolveKafkaTopic(CEXType.BINANCE, KafkaUtil.getKLineStreamName(symbol, kLineInterval), runEnv, tradeType);

        log.info("收到k线信息 - {}, - {} - {} - {} send to topic[{}]", symbol, data, runEnv, tradeType, topic);
        try {
            kafkaProducerService.sendMessage(
                    topic,
                    data.toJSONString()
            ).get();
        } catch (InterruptedException | ExecutionException e) {
            log.error("保持k线信息到kafka出错，symbol[{}]", symbol, e);
        }
    }

    /**
     * 创建topic
     *
     * @param kLines    k线list
     * @param runEnv    运行环境
     * @param tradeType 交易类型
     */
    private void createTopic(List<Pair<String, KLineInterval>> kLines, RunEnv runEnv, TradeType tradeType) {
        for (Pair<String, KLineInterval> kLine : kLines) {
            String topic = KafkaUtil.resolveKafkaTopic(CEXType.BINANCE, KafkaUtil.getKLineStreamName(kLine.getKey(), kLine.getValue()), runEnv, tradeType);

            kafkaProducerService.checkAndCreateTopic(
                    topic,
                    realtimeConfig.getKafka().getKafka_num_partitions(),
                    realtimeConfig.getKafka().getKafka_replication_factor()
            );
        }
    }
}



package com.helei.reaktimedatacenter.service.impl.market;

import cn.hutool.core.lang.Pair;
import com.helei.binanceapi.BinanceWSMarketStreamClient;
import com.helei.binanceapi.base.AbstractBinanceWSApiClient;
import com.helei.binanceapi.base.SubscribeResultInvocationHandler;
import com.helei.binanceapi.constants.BinanceWSClientType;
import com.helei.cexapi.manager.BinanceBaseClientManager;
import com.helei.constants.trade.KLineInterval;
import com.helei.constants.RunEnv;
import com.helei.constants.trade.TradeType;
import com.helei.reaktimedatacenter.manager.ExecutorServiceManager;
import com.helei.reaktimedatacenter.realtime.impl.BinanceKLineRTDataSyncTask;
import com.helei.reaktimedatacenter.service.impl.KafkaProducerService;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;

import java.util.List;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;


/**
 * 币安市场数据服务
 */
@Slf4j
@Service
public class BinanceMarketRTDataService extends AbstractKafkaMarketRTDataService {

    @Autowired
    private BinanceBaseClientManager binanceBaseClientManager;


    @Autowired
    public BinanceMarketRTDataService(ExecutorServiceManager executorServiceManager, KafkaProducerService kafkaProducerService) {
        super(executorServiceManager.getKlineTaskExecutor(), kafkaProducerService);
    }

    @Override
    protected CompletableFuture<Void> registryKLineDataLoader(
            RunEnv runEnv,
            TradeType tradeType,
            List<Pair<String, KLineInterval>> listenKLines,
            SubscribeResultInvocationHandler whenReceiveKLineData,
            ExecutorService executorService
    ) throws ExecutionException, InterruptedException {
        AbstractBinanceWSApiClient client = binanceBaseClientManager.getEnvTypedApiClient(runEnv, tradeType, BinanceWSClientType.MARKET_STREAM).get();
        BinanceWSMarketStreamClient marketStreamClient = (BinanceWSMarketStreamClient) client;

        return new BinanceKLineRTDataSyncTask(
                marketStreamClient,
                listenKLines
        ).startSync(whenReceiveKLineData, taskExecutor);
    }
}


package com.helei.reaktimedatacenter.service.impl.market;

import cn.hutool.core.lang.Pair;
import com.alibaba.fastjson.JSONObject;
import com.helei.binanceapi.base.SubscribeResultInvocationHandler;
import com.helei.constants.RunEnv;
import com.helei.constants.WebSocketStreamParamKey;
import com.helei.constants.trade.KLineInterval;
import com.helei.constants.trade.TradeType;
import com.helei.reaktimedatacenter.manager.ExecutorServiceManager;
import com.helei.reaktimedatacenter.service.impl.KafkaProducerService;
import org.springframework.stereotype.Service;

import java.time.LocalDateTime;
import java.time.ZoneOffset;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Random;
import java.util.concurrent.*;


/**
 * 随机市场数据服务
 */
@Service
public class RandomMarketRTDataService extends AbstractKafkaMarketRTDataService {

    private final Random random = new Random();

    private final Double maxPrice = 99999.09;

    private final Double minPrice = 111.229;

    private final ConcurrentHashMap<String, ConcurrentHashMap<KLineInterval, Long>> startTimeStampMap;

    private final ConcurrentHashMap<String, ConcurrentHashMap<KLineInterval, Long>> realTimerMap;

    private final LocalDateTime startTimeStamp = LocalDateTime.of(2022, 1, 1, 1, 1);

    private long epochMilli;


    public RandomMarketRTDataService(
            ExecutorServiceManager executorServiceManager, KafkaProducerService kafkaProducerService
    ) {
        super(executorServiceManager.getKlineTaskExecutor(), kafkaProducerService);

        epochMilli = startTimeStamp.toInstant(ZoneOffset.UTC).toEpochMilli();

        if (epochMilli > System.currentTimeMillis()) {
            epochMilli = System.currentTimeMillis();
        }
        this.startTimeStampMap = new ConcurrentHashMap<>();
        this.realTimerMap = new ConcurrentHashMap<>();
    }

    @Override
    protected CompletableFuture<Void> registryKLineDataLoader(
            RunEnv runEnv,
            TradeType tradeType,
            List<Pair<String, KLineInterval>> listenKLines,
            SubscribeResultInvocationHandler whenReceiveKLineData,
            ExecutorService executorService
    ) {
        return CompletableFuture.runAsync(() -> {
            String key = getKey(runEnv, tradeType);
            for (Pair<String, KLineInterval> listenKLine : listenKLines) {
                String symbol = listenKLine.getKey();
                KLineInterval interval = listenKLine.getValue();

                startTimeStampMap.putIfAbsent(key, new ConcurrentHashMap<>());
                realTimerMap.putIfAbsent(key, new ConcurrentHashMap<>());

                startTimeStampMap.get(key).putIfAbsent(interval, epochMilli);
                realTimerMap.get(key).putIfAbsent(interval, epochMilli);

                executorService.execute(() -> {
                    Map<String, Object> map = new HashMap<>();
                    map.put(WebSocketStreamParamKey.KLINE_INTERVAL, interval);
                    while (true) {
                        try {
                            JSONObject kLine = loadKLine(runEnv, tradeType, symbol, interval);
                            whenReceiveKLineData.invoke(symbol, map, kLine);
                            TimeUnit.SECONDS.sleep(10);
                        } catch (InterruptedException e) {
                            throw new RuntimeException(e);
                        }
                    }
                });
            }

        }, executorService);
    }


    protected JSONObject loadKLine(
            RunEnv runEnv,
            TradeType tradeType,
            String symbol,
            KLineInterval kLineInterval
    ) {

        double nextLow = minPrice + (maxPrice - minPrice) * random.nextDouble();
        double nextHigh = nextLow + (maxPrice - nextLow) * random.nextDouble();
        double nextOpen = nextLow + (nextHigh - nextLow) * random.nextDouble();
        double nextClose = nextLow + (nextHigh - nextLow) * random.nextDouble();

        double volume = 10 + (Double.MAX_VALUE / 2 - 10) * random.nextDouble();
        long plus = kLineInterval.getSecond() * 1000;
        String key = getKey(runEnv, tradeType);
        long openTime = startTimeStampMap.get(key).get(kLineInterval);

        realTimerMap.get(key).computeIfPresent(kLineInterval, (k, v) -> v + 200);
        long curTime = realTimerMap.get(key).get(kLineInterval);

        boolean isRealTime = curTime > System.currentTimeMillis() - kLineInterval.getSecond() * 1000;
        if (isRealTime) {
            if (curTime >= openTime + plus) {
                openTime += plus;
                startTimeStampMap.get(key).put(kLineInterval, openTime);
            }
        } else {
            openTime += plus;
            startTimeStampMap.get(key).put(kLineInterval, openTime);
        }

        JSONObject jb = new JSONObject();
        jb.put("t", openTime);
        jb.put("T", openTime + plus - 1000);
        jb.put("s", symbol);
        jb.put("h", nextHigh);
        jb.put("l", nextLow);
        jb.put("o", nextOpen);
        jb.put("c", nextClose);
        jb.put("v", volume);
        jb.put("x", !isRealTime);
        jb.put("i", kLineInterval.name());

        return jb;
    }

    private String getKey(RunEnv runEnv, TradeType tradeType) {
        return runEnv.name() + " - " + tradeType.name();
    }
}

package com.helei.reaktimedatacenter.service.impl;

import com.alibaba.fastjson.JSONObject;
import com.helei.binanceapi.config.BinanceApiConfig;
import com.helei.cexapi.CEXApiFactory;
import com.helei.constants.RunEnv;
import com.helei.constants.trade.TradeType;
import com.helei.dto.ASKey;
import com.helei.dto.account.AccountPositionConfig;
import com.helei.dto.account.AccountRTData;
import com.helei.dto.account.UserAccountInfo;
import com.helei.dto.account.UserInfo;
import com.helei.dto.base.KeyValue;
import com.helei.reaktimedatacenter.config.RealtimeConfig;
import com.helei.reaktimedatacenter.service.UserService;
import com.helei.reaktimedatacenter.supporter.BatchWriteSupporter;
import com.helei.util.RedisKeyUtil;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.InitializingBean;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;

import java.util.ArrayList;
import java.util.List;


@Slf4j
@Service
public class UserServiceImpl implements UserService, InitializingBean {

    private final RealtimeConfig realtimeConfig = RealtimeConfig.INSTANCE;

    @Autowired
    private BatchWriteSupporter batchWriteSupporter;


    @Override
    public List<UserInfo> queryAll() {

        for (KeyValue<RunEnv, TradeType> keyValue : realtimeConfig.getRun_type().getRunTypeList()) {
            //TODO 查数据库, 只取这些环境里的

        }
        List<UserInfo> list = new ArrayList<>();

        UserInfo u_contract_test_net_account = UserInfo.builder()
                .id(1)
                .username("合约测试网账号")
                .password("123456")
                .accountInfos(List.of(
                        UserAccountInfo
                                .builder()
                                .id(1)
                                .userId(1)
                                .accountPositionConfig(AccountPositionConfig
                                        .builder()
                                        .riskPercent(0.5)
                                        .leverage(10)
                                        .build()
                                )
                                .asKey(new ASKey("b252246c6c6e81b64b8ff52caf6b8f37471187b1b9086399e27f6911242cbc66", "a4ed1b1addad2a49d13e08644f0cc8fc02a5c14c3511d374eac4e37763cadf5f"))
                                .subscribeSymbol(List.of("btcusdt", "ethusdt", "solusdt"))
                                .runEnv(RunEnv.TEST_NET)
                                .tradeType(TradeType.CONTRACT)
                                .build()
                ))
                .build();
        UserInfo spot_test_net_account = UserInfo.builder()
                .id(2)
                .username("现货测试网账号")
                .password("123456")
                .accountInfos(List.of(
                        UserAccountInfo
                                .builder()
                                .id(2)
                                .userId(2)
                                .accountPositionConfig(AccountPositionConfig
                                        .builder()
                                        .riskPercent(0.5)
                                        .leverage(10)
                                        .build()
                                )
                                .subscribeSymbol(List.of("btcusdt", "ethusdt", "solusdt"))
                                .asKey(new ASKey("1JIhkPyK07xadG9x8hIwqitN95MgpypPzA4b6TLraTonRnJ8BBJQlaO2iL9tPH0Y", "t84TYFR1zieMGncbw3kYq4zAPLxIJHJeMdD8V0FMKxij9fApojV6bhbDpyyjNDWt"))
                                .runEnv(RunEnv.TEST_NET)
                                .tradeType(TradeType.SPOT)
                                .build()
                ))
                .build();

        UserInfo binance_account = UserInfo.builder()
                .id(3)
                .username("正式网账号")
                .password("123456")
                .accountInfos(List.of(
                        UserAccountInfo
                                .builder()
                                .id(3)
                                .userId(3)
                                .accountPositionConfig(AccountPositionConfig
                                        .builder()
                                        .riskPercent(0.5)
                                        .leverage(10)
                                        .build()
                                )
                                .subscribeSymbol(List.of("btcusdt", "ethusdt", "solusdt"))
                                .asKey(new ASKey("TUFsFL4YrBsR4fnBqgewxiGfL3Su5L9plcjZuyRO3cq6M1yuwV3eiNX1LcMamYxz", "YsLzVacYo8eOGlZZ7RjznyWVjPHltIXzZJz2BrggCmCUDcW75FyFEv0uKyLBVAuU"))
                                .runEnv(RunEnv.NORMAL)
                                .tradeType(TradeType.SPOT)
                                .build()
                ))
                .build();


        list.add(u_contract_test_net_account);
        list.add(spot_test_net_account);
        list.add(binance_account);
        return list;
    }


    /**
     * 更新用户账户信息
     *
     * @param userAccountInfo userAccountInfo
     */
    @Override
    public void updateUserAccountInfo(UserAccountInfo userAccountInfo) {

        long accountId = userAccountInfo.getId();
        long userId = userAccountInfo.getUserId();

        String key = RedisKeyUtil.getUserAccountEnvRTDataKey(userAccountInfo.getRunEnv(), userAccountInfo.getTradeType());
        String hashKey = String.valueOf(accountId);

        //只发实时的部分数据
        String value = JSONObject.toJSONString(new AccountRTData(userId, accountId, userAccountInfo.getAccountBalanceInfo(), userAccountInfo.getAccountPositionInfo()));

        log.info("更新账户信息，key[{}], value[{}]", key, value);
//        batchWriteSupporter.writeToRedis(key, value);
        batchWriteSupporter.writeToRedisHash(key, hashKey, value);
    }

    /**
     * 更新UserInfo到Redis，包括User名下的账户信息
     *
     * @param env       运行环境
     * @param tradeType 交易类型
     */
    public void updateUserInfoToRedis(RunEnv env, TradeType tradeType) {
        List<UserInfo> userInfos = queryAll();
        for (UserInfo userInfo : userInfos) {

            String key = RedisKeyUtil.getUserInfoKeyPrefix(env, tradeType) + userInfo.getId();
            batchWriteSupporter.writeToRedis(key, JSONObject.toJSONString(userInfo));
        }
    }

    @Override
    public void afterPropertiesSet() throws Exception {
        for (KeyValue<RunEnv, TradeType> keyValue : realtimeConfig.getRun_type().getRunTypeList()) {
            updateUserInfoToRedis(keyValue.getKey(), keyValue.getValue());
        }
    }
}

package com.helei;

import com.helei.reaktimedatacenter.service.AccountEventStreamService;
import com.helei.reaktimedatacenter.service.MarketRealtimeDataService;
import com.helei.reaktimedatacenter.service.impl.market.RandomMarketRTDataService;
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.context.ConfigurableApplicationContext;

/**
 * 实时数据中心
 */
@SpringBootApplication
public class RealtimeDataCenter {
    public static void main(String[] args) {
        ConfigurableApplicationContext applicationContext = SpringApplication.run(RealtimeDataCenter.class, args);


//        startRTDataStream(applicationContext);
//
        startAccountEventStream(applicationContext);
    }

    private static void startAccountEventStream(ConfigurableApplicationContext applicationContext) {
        AccountEventStreamService accountEventStreamService = applicationContext.getBean(AccountEventStreamService.class);
        accountEventStreamService.startAllUserInfoEventStream();
    }

    private static void startRTDataStream(ConfigurableApplicationContext applicationContext) {
        MarketRealtimeDataService marketRealtimeDataService = applicationContext.getBean(RandomMarketRTDataService.class);
        marketRealtimeDataService.startSyncRealTimeKLine();
    }
}




package com.helei.reaktimedatacenter.service.impl;

import com.helei.dto.account.UserInfo;
import com.helei.reaktimedatacenter.service.impl.account.BinanceAccountEventStreamService;
import org.junit.jupiter.api.AfterEach;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;

import java.util.List;
import java.util.concurrent.TimeUnit;

@SpringBootTest
class BinanceAccountEventStreamServiceTest {

    @Autowired
    private UserServiceImpl userService;

    @Autowired
    private BinanceAccountEventStreamService binanceAccountEventStreamService;

    @BeforeEach
    void setUp() {
    }

    @AfterEach
    void tearDown() {
    }

    @Test
    void startAllUserInfoEventStream() {
        binanceAccountEventStreamService.startAllUserInfoEventStream();

    }

    @Test
    void startUserInfoEventStream() throws InterruptedException {

        List<UserInfo> userInfos = userService.queryAll();

        UserInfo first = userInfos.getFirst();
        UserInfo two = userInfos.get(1);
        UserInfo three = userInfos.get(2);

        binanceAccountEventStreamService.startUserInfoEventStream(three);

        TimeUnit.MINUTES.sleep(1000);
    }
}



package com.helei.service.impl;

import com.helei.constants.RunEnv;
import com.helei.constants.trade.TradeType;
import com.helei.reaktimedatacenter.service.impl.market.BinanceMarketRTDataService;
import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;

import java.util.concurrent.TimeUnit;

@SpringBootTest
class BinanceMarketRTDataServiceTest {

    @Autowired
    private BinanceMarketRTDataService binanceMarketRTDataService;



    @Test
    void startSyncRealTimeKLine() throws InterruptedException {
        binanceMarketRTDataService.startSyncRealTimeKLine(RunEnv.TEST_NET, TradeType.SPOT);

        TimeUnit.MINUTES.sleep(1000);
    }
}




package com.helei.tradesignalprocess.stream.a_klinesource.impl;

import cn.hutool.core.collection.ConcurrentHashSet;
import com.helei.binanceapi.BinanceWSReqRespApiClient;
import com.helei.binanceapi.api.rest.BinanceUContractMarketRestApi;
import com.helei.binanceapi.base.AbstractBinanceWSApiClient;
import com.helei.binanceapi.config.BinanceApiConfig;
import com.helei.binanceapi.constants.BinanceWSClientType;
import com.helei.cexapi.CEXApiFactory;
import com.helei.cexapi.manager.BinanceBaseClientManager;
import com.helei.constants.trade.KLineInterval;
import com.helei.constants.trade.TradeType;
import com.helei.dto.base.KeyValue;
import com.helei.dto.config.RunTypeConfig;
import com.helei.dto.trade.KLine;
import com.helei.constants.RunEnv;
import com.helei.tradesignalprocess.config.TradeSignalConfig;
import com.helei.tradesignalprocess.stream.a_klinesource.HistoryKLineLoader;
import com.helei.tradesignalprocess.stream.a_klinesource.KLineHisAndRTSource;
import com.helei.tradesignalprocess.stream.a_klinesource.KafkaRealTimeSourceFactory;
import lombok.extern.slf4j.Slf4j;
import org.apache.flink.configuration.Configuration;
import org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.KafkaConsumer;
import org.jetbrains.annotations.NotNull;

import javax.net.ssl.SSLException;
import java.net.URISyntaxException;
import java.time.Duration;
import java.time.Instant;
import java.util.Set;
import java.util.concurrent.*;


/**
 * 币安历史k线和实时k线Flink数据源
 * <p>一个BinanceKLineHisAndReTSource代表一个交易对（symbol）下的k线数据源， 可以有不同的KLineInterval</p>
 * <p>1.先根据startTime获取历史数据，历史数据获取完毕后才向flink source 中加入实时的数据</p>
 * <p>2.实时数据在启动时就通过KafkaConsumer开始统一获取，只是要等到历史数据获取完毕才写入flink source</p>
 */
@Slf4j
public class BinanceKLineHisAndRTSource extends KLineHisAndRTSource {

    /**
     * 相关回调执行的线程池
     */
    private transient ExecutorService executor;

    /**
     * 已加载完毕的历史k线
     */
    private transient ConcurrentHashSet<KLineInterval> historyLoadedIntervals;

    /**
     * 币安基础WS客户端管理器
     */
    private transient BinanceBaseClientManager binanceBaseClientManager;

    /**
     * binance api config
     */
    private final BinanceApiConfig binanceApiConfig;


    protected BinanceKLineHisAndRTSource(
            String symbol,
            Set<KLineInterval> kLineIntervals,
            long startTime
    ) {
        super(symbol, kLineIntervals, startTime);
        this.binanceApiConfig = BinanceApiConfig.INSTANCE;
    }

    @Override
    public void onOpen(Configuration parameters) throws Exception {
        historyLoadedIntervals = new ConcurrentHashSet<>();
        // TODO 线程池管理
        executor = Executors.newVirtualThreadPerTaskExecutor();
        binanceBaseClientManager = CEXApiFactory.binanceBaseWSClientManager(TradeSignalConfig.TRADE_SIGNAL_CONFIG.getRun_type(), executor);
    }

    @Override
    public void loadDataInBuffer(BlockingQueue<KLine> buffer) {

        int batchSize = tradeSignalConfig.getHistoryKLineBatchSize();
        TradeType tradeType = tradeSignalConfig.getTrade_type();
        Instant startInstant = Instant.ofEpochMilli(startTime);


        //Step 1: 初始化HistoryKLineLoader
        HistoryKLineLoader historyKLineLoader = initHistoryKLineLoader(tradeSignalConfig.getRun_type(), batchSize, executor);

        //Step 2: 遍历k线频率列表，开始加载历史k线数据
        for (KLineInterval interval : intervals) {
            CompletableFuture
                    .supplyAsync(() -> {
                        //Step 2.1: 获取历史k线，写入sourceContext
                        log.info("开始获取历史k线数据, symbol[{}], interval[{}], startTime[{}]",
                                symbol, interval, startInstant);

                        CompletableFuture<Long> future = historyKLineLoader.startLoad(symbol, interval, startTime, kLines -> {
                            log.info("获取到历史k线批数据 [{}]-[{}]: {}", symbol, interval, kLines.size());
                            for (KLine kLine : kLines) {
                                kLine.setSymbol(symbol);
                                buffer.add(kLine);
                            }
                        });
                        try {
                            future.get();
                            log.info("symbol[{}], interval[{}]历史k线数据获取完毕", symbol, interval);
                        } catch (InterruptedException | ExecutionException e) {
                            log.error("加载历史k线数据出错", e);
                            System.exit(-1);
                        }
                        return interval;
                    }, executor)
                    .thenAcceptAsync(itv -> {
                        //Step 2.2: 历史k线获取完毕后记录状态
                        historyLoadedIntervals.add(itv);

                        if (historyLoadedIntervals.size() == intervals.size()) {
                            //所有历史k线获取完毕，关闭客户端
                            log.info("所有历史k线获取完毕");
                            historyKLineLoader.closeClient();
                        }
                    }, executor)
                    .exceptionally(e -> {
                        log.error("异步任务执行异常", e);
                        return null;
                    });
        }


        //Step 3: 获取实时k线，写入buffer
        CompletableFuture.runAsync(() -> {
            KafkaRealTimeSourceFactory sourceFactory = new KafkaRealTimeSourceFactory(symbol, intervals);

            KafkaConsumer<String, KLine> rtConsumer = sourceFactory
                    .loadRTKLineStream(BinanceApiConfig.cexType, tradeSignalConfig.getRun_env(), tradeType);
            while (isRunning) {
                ConsumerRecords<String, KLine> records = rtConsumer.poll(Duration.ofMillis(100));
                for (ConsumerRecord<String, KLine> record : records) {
                    KLine kline = record.value();
                    // 只有当历史k线数据加载完毕，才会向写入buffer中加入实时数据
                    KLineInterval kLineInterval = kline.getKLineInterval();
                    if ((kLineInterval != null && historyLoadedIntervals.contains(kLineInterval))) {
                        buffer.add(kline);
                    }
                }
            }
        }, executor).exceptionally(e -> {
            log.error("加载实时数据出错", e);
            return null;
        });
    }

    /**
     * 初始化历史k线加载器
     *
     * @param runTypeConfig    runTypeConfig
     * @param batchSize batchSize
     * @param executor  executor
     * @return HistoryKLineLoader
     */
    @NotNull
    private HistoryKLineLoader initHistoryKLineLoader(
            RunTypeConfig runTypeConfig,
            int batchSize,
            ExecutorService executor
    ) {
        HistoryKLineLoader historyKLineLoader;
        try {
            KeyValue<RunEnv, TradeType> keyValue = runTypeConfig.getRunTypeList().getFirst();

            historyKLineLoader = switch (keyValue.getValue()) {
                case SPOT -> spotHistoryKLineLoader(runTypeConfig, batchSize, executor);
                case CONTRACT -> {
                    String historyApiUrl = getHistoryApiUrl(TradeType.CONTRACT);
                    yield contractHistoryKLineLoader(historyApiUrl, batchSize, executor);
                }
            };
        } catch (Exception e) {
            throw new RuntimeException("获取历史k线数据加载器失败", e);
        }
        return historyKLineLoader;
    }

    /**
     * 获取现货历史k线数据加载器
     *
     * @param runTypeConfig runTypeConfig
     * @param batchSize     batchSize
     * @param executor      executor
     * @return HistoryKLineLoader
     */
    @NotNull
    private HistoryKLineLoader spotHistoryKLineLoader(RunTypeConfig runTypeConfig, int batchSize, ExecutorService executor) throws URISyntaxException, SSLException, InterruptedException, ExecutionException {
        RunTypeConfig.RunEnvTradeTypeConfig first = runTypeConfig.getConfigs().getFirst();

        AbstractBinanceWSApiClient client = binanceBaseClientManager.getEnvTypedApiClient(first.getEnv(), first.getTrade_type().getFirst(), BinanceWSClientType.MARKET_STREAM).get();

        return new HistoryKLineLoader(batchSize, (BinanceWSReqRespApiClient) client, executor);
    }


    /**
     * 获取合约历史k线数据加载器
     * <p>由于合约币安没提供k线数据的websocket的获取方式，所以用的rest api</p>
     *
     * @param historyApiUrl historyApiUrl
     * @param batchSize     batchSize
     * @param executor      executor
     * @return HistoryKLineLoader
     */
    @NotNull
    private HistoryKLineLoader contractHistoryKLineLoader(String historyApiUrl, int batchSize, ExecutorService executor) {
        BinanceUContractMarketRestApi binanceUContractMarketRestApi = CEXApiFactory.binanceUContractMarketRestApi(historyApiUrl, executor);
        return new HistoryKLineLoader(batchSize, binanceUContractMarketRestApi, executor);
    }


    /**
     * 获取请求历史数据的api url
     *
     * @return url
     */
    protected String getHistoryApiUrl(TradeType tradeType) {
        if (RunEnv.NORMAL.equals(tradeSignalConfig.getRun_env())) {
            return switch (tradeType) {
                case SPOT -> binanceApiConfig.getNormal().getSpot().getWs_market_url();
                case CONTRACT -> binanceApiConfig.getNormal().getU_contract().getRest_api_url();
            };
        } else {
            return switch (tradeType) {
                case SPOT -> binanceApiConfig.getTest_net().getSpot().getWs_market_url();
                case CONTRACT -> binanceApiConfig.getTest_net().getU_contract().getRest_api_url();
            };
        }
    }
}

package com.helei.tradesignalprocess.stream.a_klinesource;

import com.alibaba.fastjson.JSONArray;
import com.helei.binanceapi.BinanceWSMarketStreamClient;
import com.helei.binanceapi.BinanceWSReqRespApiClient;
import com.helei.binanceapi.api.rest.BinanceUContractMarketRestApi;
import com.helei.constants.trade.KLineInterval;
import com.helei.binanceapi.supporter.KLineMapper;
import com.helei.dto.trade.KLine;
import com.helei.tradesignalprocess.config.TradeSignalConfig;
import lombok.extern.slf4j.Slf4j;

import java.time.LocalDateTime;
import java.time.ZoneOffset;
import java.util.Iterator;
import java.util.LinkedList;
import java.util.List;
import java.util.concurrent.*;
import java.util.function.Consumer;
import java.util.stream.Collectors;

/**
 * 历史k线数据源
 */
@Slf4j
public class HistoryKLineLoader {
    private final transient Semaphore semaphore;

    private final transient BinanceWSReqRespApiClient reqRespApiClient;

    private final transient BinanceUContractMarketRestApi binanceUContractMarketRestApi;

    private final transient ExecutorService loadThreadPool;

    private final int limit;


    /**
     * 传入websocket api,通过ws获取k线数据
     * @param limit limit
     * @param reqRespApiClient reqRespApiClient
     * @param loadThreadPool loadThreadPool
     */
    public HistoryKLineLoader(
            int limit,
            BinanceWSReqRespApiClient reqRespApiClient,
            ExecutorService loadThreadPool
    ) {
        this(limit, reqRespApiClient, null, loadThreadPool);
    }

    /**
     * 传入binanceUContractMarketRestApi, 传入restapi，通过http请求获取k线数据
     * @param limit limit
     * @param binanceUContractMarketRestApi binanceUContractMarketRestApi
     * @param loadThreadPool loadThreadPool
     */
    public HistoryKLineLoader(
            int limit,
            BinanceUContractMarketRestApi binanceUContractMarketRestApi,
            ExecutorService loadThreadPool
    ) {
        this(limit, null, binanceUContractMarketRestApi, loadThreadPool);
    }

    public HistoryKLineLoader(
            int limit,
            BinanceWSReqRespApiClient reqRespApiClient,
            BinanceUContractMarketRestApi binanceUContractMarketRestApi,
            ExecutorService loadThreadPool
    ) {
        this.limit = limit;
        this.reqRespApiClient = reqRespApiClient;
        this.binanceUContractMarketRestApi = binanceUContractMarketRestApi;
        this.loadThreadPool = loadThreadPool;
        this.semaphore = new Semaphore(TradeSignalConfig.TRADE_SIGNAL_CONFIG.getBatchLoadConcurrent());
    }

    /**
     * 开始加载k线数据
     * @param symbol symbol
     * @param interval interval
     * @param startTime startTime
     * @param batchKLineConsumer batchKLineConsumer
     * @return 最后完成的时间
     */
    public CompletableFuture<Long> startLoad(
            String symbol,
            KLineInterval interval,
            long startTime,
            Consumer<List<KLine>> batchKLineConsumer
    ) {
        String upperSymbol = symbol.toUpperCase();
        return CompletableFuture.supplyAsync(() -> {
            LinkedList<CompletableFuture<List<KLine>>> waitWindow = new LinkedList<>();

            long curTimeSecond = (long) (startTime / 1000.0);

            while (curTimeSecond  <= LocalDateTime.now().toInstant(ZoneOffset.UTC).getEpochSecond()) {

                CompletableFuture<List<KLine>> batchLoadFuture = batchLoadKLine(interval, upperSymbol, curTimeSecond);

                waitWindow.add(batchLoadFuture);
                curTimeSecond += interval.getSecond() * limit;
            }

            Iterator<CompletableFuture<List<KLine>>> iterator = waitWindow.iterator();
            while (iterator.hasNext()) {
                CompletableFuture<List<KLine>> batchLoadFuture = iterator.next();
                List<KLine> lines = batchLoadFuture.join();
                batchKLineConsumer.accept(lines);
                iterator.remove();
            }

            return curTimeSecond;
        }, loadThreadPool);
    }

    /**
     * 批加载k线数据
     * @param interval interval
     * @param upperSymbol upperSymbol
     * @param curTimeSecond curTimeSecond
     * @return CompletableFuture<List<KLine>>
     */
    private CompletableFuture<List<KLine>> batchLoadKLine(KLineInterval interval, String upperSymbol, long curTimeSecond) {
        return CompletableFuture.supplyAsync(()->{
            //控制网络并发
            try {
                semaphore.acquire();
                return batchLoadKLineNetwork(interval, upperSymbol, curTimeSecond).get();
            } catch (Exception e) {
                throw new RuntimeException(e);
            } finally {
                semaphore.release();
            }
        }, loadThreadPool);
    }

    private CompletableFuture<List<KLine>> batchLoadKLineNetwork(KLineInterval interval, String upperSymbol, long curTimeSecond) {
        if (reqRespApiClient != null) {
            return reqRespApiClient
                    .getMarketApi()
                    .queryHistoryKLine(upperSymbol, interval, curTimeSecond, limit)
                    .thenApplyAsync(result -> {
                        JSONArray jsonArray = result.getJSONArray("result");

                        List<KLine> collect = jsonArray.stream().map(e -> {
                            JSONArray kArr = (JSONArray) e;
                            KLine e1 = KLineMapper.mapJsonArrToKLine(kArr);
                            e1.setSymbol(upperSymbol);
                            return e1;
                        }).collect(Collectors.toList());

                        log.debug("history kline [{}]", collect);
                        return collect;
                    }, loadThreadPool);
        } else if (binanceUContractMarketRestApi != null) {
            return binanceUContractMarketRestApi.queryKLines(upperSymbol, interval, curTimeSecond, null, limit);
        } else {
            log.error("没有设置获取k线的apiClient");
            throw new IllegalArgumentException("没有设置获取k线的apiClient");
        }
    }

    /**
     * 关闭客户端
     */
    public void closeClient() {
        if (reqRespApiClient != null) {
            log.info("关闭客户端[{}]", reqRespApiClient.getName());
            reqRespApiClient.close();
        }
    }
}




